<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<link rel="icon" href="../favicon.png" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		
		<link href="../_app/immutable/assets/0.-Q-4U8s6.css" rel="stylesheet">
		<link rel="modulepreload" href="../_app/immutable/entry/start.DPC-yaMZ.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/entry.LlyxVWRv.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/scheduler.BeaK0CkN.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/paths.B_cnpgLP.js">
		<link rel="modulepreload" href="../_app/immutable/entry/app.BetbdFog.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/index.CxzZzLz5.js">
		<link rel="modulepreload" href="../_app/immutable/nodes/0.ChMGXpx4.js">
		<link rel="modulepreload" href="../_app/immutable/nodes/3.BLqwFAv-.js">
	</head>
	<body data-sveltekit-preload-data="hover">
		<div style="display: contents">  <div class="mx-auto flex flex-col mx-4 w-[98%] lg:w-[75%] xl:w-[60%]"><div class="mt-8 text-2xl text-center" data-svelte-h="svelte-py3wln">Modeling Chaotic Dynamics with Deep Learning: A Case Study on the Lorenz Attractor</div> <div class="mt-2 text-sm text-center" data-svelte-h="svelte-hve5fy">Michael Horgan</div> <br> <p class="my-2 indent-8 ">This project is inspired by several recent publications involving the use of deep learning
		to predict or control chaotic dynamical systems, in particular William Gilpin&#39;s paper, <i data-svelte-h="svelte-1orr88l">Model scale versus domain knowledge in statistical forecasting of chaotic systems</i> [<a href="https://link.aps.org/doi/10.1103/PhysRevResearch.5.043252" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">1</a>]. Gilpin found that, given enough training data, generic neural
		architectures can match or exceed the performance of state-of-the-art domain-specific
		choatic forecasting models such as reservoir computers and neural ODEs. Although I have
		never studied dynamical systems in depth, I have recently become highly intrigued by the
		prospect of applying deep learning to prediction tasks involving chaotic systems, as I
		explore ways to contribute to the efforts to find technical solutions to climate change.
		Along with Gilpin&#39;s paper, there have been several recent publications on the subject that
		were especially exciting to me, particularly the ones applying deep learning to tokamak
		control in nuclear fusion reactors (see e.g. [<a href="https://doi.org/10.1038/s41586-024-07024-9" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">2</a>], [<a href="https://doi.org/10.1038/s41586-021-04301-9" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">3</a>]).</p><p class="my-2 indent-8 ">My goal with this project is to get some hands-on experience with a chaotic system and
		probe deeper into Gilpin&#39;s findings by testing the limits of a neural network&#39;s ability to
		model a single chaotic system (within the computational constraints imposed by my limited
		budget*). I&#39;ll start with what is probably the most well known chaotic system, the Lorenz
		Attractor. As my dynamical systems background is a bit rusty, I will be (re)discovering many
		of the properties of the Lorenz System, and dynamical systems in general, as I go, often
		using the results of my experiments to guide my investigation. What exactly makes the Lorenz
		Attractor chaotic? And what constraints will that impose on the ability of a deep neural
		network to model it? Let&#39;s find out!</p> <div class="my-4 mx-16 text-sm font-serif -indent-16"><p data-svelte-h="svelte-a477ex">* All of my experiments were run on a Paperspace VM using two RTX 5000s, each with 16 GB
			of RAM.</p> <p>note: All code used in this project is available in my github repo: <a href="https://github.com/nrxszvo/mochaNN" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">mochaNN</a></p> <p>note: For a quick and entertaining way to stay informed of new developments in the world
			of DL for dynamical systems modeling, I highly recommend Sabine Hossenfelder&#39;s <a href="https://www.youtube.com/@SabineHossenfelder" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">Youtube channel</a></p> <p>note: If you would like to refresh your background on dynamical systems theory, I highly
			recommend Steve Brunton&#39;s free <a href="https://www.youtube.com/playlist?list=PLMrJAkhIeNNTYaOnVI3QpH7jgULnAmvPA" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">lecture series</a> on the subject</p></div> <div class="text-2xl text-center mt-4 mb-2">The Lorenz Attractor</div> <p class="my-2 indent-8 ">The
		<a href="https://en.wikipedia.org/wiki/Lorenz_system" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">Lorenz Attractor</a> was developed
		by Edward Lorenz et. al. in 1963 as a simplified model of atmospheric convection.</p> <div class="my-2 self-center"><a title="Dan Quinn, CC BY-SA 3.0 <https://creativecommons.org/licenses/by-sa/3.0>, via Wikimedia Commons" href="https://commons.wikimedia.org/wiki/File:A_Trajectory_Through_Phase_Space_in_a_Lorenz_Attractor.gif"><figure><img class="m-auto" width="128" alt="A Trajectory Through Phase Space in a Lorenz Attractor" src="https://upload.wikimedia.org/wikipedia/commons/1/13/A_Trajectory_Through_Phase_Space_in_a_Lorenz_Attractor.gif"> <figcaption class="text-center text-xs mt-2 mx-36">The Lorenz Attractor</figcaption></figure></a></div> <p class="my-2 indent-8 ">The Lorenz system is comprised of three ordinary differential equations representing the
		properties of convection and horizontal and vertical temperature in a two-dimensional fluid
		layer:</p> <div class="self-center"><p>
\begin{align}
\dot{x} &amp; = \sigma(y-x) \\
\dot{y} &amp; = \rho x - y - xz \\
\dot{z} &amp; = -\beta z + xy
\end{align}</p></div> <p class="my-2 indent-8 ">The Lorenz <i data-svelte-h="svelte-7jrnvq">Attractor</i> refers to a set of chaotic solutions to the system, most commonly:</p> <div class="self-center"><p>
\begin{align}
\sigma &amp; = 10 \\
\beta &amp; = \frac{8}{3} \\
\rho &amp; = 28 \\
\end{align}</p></div> <p class="my-2 indent-8 ">I used Gilpin&#39;s <a href="https://github.com/williamgilpin/dysts" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">dysts</a> python module
		to generate the training data for this solution.</p> <div class="text-2xl text-center mt-4 mb-2">Neural Architecture: N-HiTS</div> <p class="my-2 indent-8 ">The N-HiTS [<a href="https://arxiv.org/abs/2201.12886" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">4</a>] forecasting network is known to produce state-of-the-art results,
		at the time of writing, for univariate time series prediction, with up to an order of magnitude
		lower computational requirement than some competitors. Given my limited budget and its strong
		performance reported in [<a href="https://link.aps.org/doi/10.1103/PhysRevResearch.5.043252" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">1</a>], it seemed like the natural starting point for a
		network architecture.</p> <p class="my-2 indent-8 ">The architectural ideas in N-HiTS build on those of its predecessor, N-BEATS [<a href="https://arxiv.org/abs/1905.10437" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">5</a>], a neural basis expansion network for time series prediction. The key ideas inherited
		from N-BEATS include the organization of fully connected layers into blocks that output
		basis expansions (linear projections of the preceding fully connected layer&#39;s output) and
		the use of both forecast and backcast predictions from each block. The forecast predictions
		from all blocks are summed together to produce the final output of the network, while the
		backcasts are subtracted from the input of the corresponding block to produce a residual
		connection as the input to the next block. The goal of the backcasts is to help the
		downstream blocks by &quot;removing components of their input that are not helpful for
		forecasting&quot; [<a href="https://arxiv.org/abs/1905.10437" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">5</a>].</p> <p class="my-2 indent-8 ">The novel ideas from N-HiTS enable the possiblity of modeling increasingly long time
		horizons while keeping computational complexity low. They include the use of pooling layers
		that downsample the inputs to each block and upsampling layers that map a compressed
		representation of the forecast to the output sample rate. In addition to the complexity
		savings, the compressed representations may induce a bias towards a temporal hierarchical
		modeling of the time series across the blocks that allows N-HiTS to exceed the performance
		of competing long-horizon forecasting models while requiring an order of magnitude lower
		computational complexity [<a href="https://arxiv.org/abs/2201.12886" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">4</a>].</p> <div class="text-2xl text-center mt-4 mb-2">Experiments</div> <p class="my-2 indent-8 ">While Gilpin&#39;s experiments focus on testing 24 different time-series prediction models on
		over 130 different chaotic systems using a relatively narrow range of hyper parameters for
		tuning [<a href="https://link.aps.org/doi/10.1103/PhysRevResearch.5.043252" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">1</a>], my experiments aim to tune a single model, N-HiTS, on a single
		system, the Lorenz Attractor, to maximize its accuracy for a given, relatively long, fixed
		horizon (aka prediction window length). And more specifically, I aim not only to achieve a
		low average error on the test set but also to limit the worst-case error as much as
		possible, which will likely mean achieving a degree of predictive power over the most
		chaotic regions of the system. Is this a completely naive aspiration given what is known
		about chaotic systems? Maybe, but I&#39;m not really sure yet, and either way this should be a
		fun learning experience...</p><div class="text-xl text-center mt-4 mb-2">Data Generation</div><p class="my-2 indent-8 ">I begin with a horizon (prediction window) of 100 points, using a $dt$ of approximately
		$0.015$ seconds per point (the default from <a href="https://github.com/williamgilpin/dysts" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">dysts</a>) to sample the solution produced by the <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.solve_ivp.html" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">IVP solver</a>. Importantly, note that this $dt$ is only the one used for sampling the solution
		<i data-svelte-h="svelte-10nlrz4">after</i>
		it is generated by the IVP solver. The actual $dt$ used internally by the IVP solver can
		vary dynamically, but the initial target value used by <a href="https://github.com/williamgilpin/dysts" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">dysts</a> is $\text{first_step} = 0.0001801$.</p><p class="my-2 indent-8 ">At this stage, it may also be worth mentioning one of the common metrics for measuring the
		average chaoticity of a system, the maximum
		<a href="https://en.wikipedia.org/wiki/Lyapunov_exponent" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">Lyapunov exponent</a>. As
		reported in
		<a href="https://github.com/williamgilpin/dysts" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">dysts</a>, the Lyapunov exponent for
		the Lorenz Attractor is approx. $0.8917$, and so the <a href="https://en.wikipedia.org/wiki/Lyapunov_time" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">Lyapunov time</a> is approx.
		$1.121s$.</p> <div class="self-center"><p>
\begin{align}
dt &amp; \approx 0.015 \mathrm{s} \\
\lambda_{max}^{-1} &amp; \approx 1.121 \mathrm{s} \\
H = 100 \text{ points} &amp; \approx 1.34\lambda_{max}^{-1} \\
\end{align}</p></div> <p class="my-2 indent-0 ">This tells us that, <i data-svelte-h="svelte-ggx8py">on average</i>, the distance between any two trajectories from the
		Lorenz Attractor are expected to diverge by a factor of $e$ after
		$1.121$ seconds. Note that with these parameters, the horizon covers a time period of about
		$\frac{4}{3}$
		of the Lyapunov time.</p><p class="my-2 indent-8 ">The train and test sets are comprised of many trajectories with initial conditions all
		centered at approx. $[-9.79, -15.04, 20.53]$ and multiplied by a random perturbation uniformly
		sampled from the interval $[0.99,1.01]$.</p> <p class="my-2 indent-0 ">The input to the N-HiTs model is a lookback window of the previous series values whose
		length is typically some multiple of the horizon window. I went with the default value from
		the N-HiTS paper of 5 times the horizon window length, or 500 points, making each training
		sample a total of 600 points. (Note that because N-HiTs is a univariate model, while the
		Lorenz System is three-dimensional, the data points must be flattened into one dimension.
		Therefore, the horizon window length is actually $3*100 = 300$, and each training
		sample&#39;s length is $3 * (500 + 100) = 1800$).</p> <p class="my-2 indent-8 ">I choose, somewhat arbitrarily, to generate 10,000 points per series, and in order to
		increase data efficiency, I select each training sample by sliding the 600-point window
		along the series with a one-point stride. Each series, therefore, contributes $10,000 - 600 +
		1 = 9401$ training samples. For the initial experiment, I generate 25 series with unique initial conditions,
		and train on 19 of them, and hold out 3 series for validation and 3 series for testing.</p> <div class="text-xl text-center mt-4 mb-2">Model 1</div> <p class="mt-2" data-svelte-h="svelte-u5zzza">The full set of N-HiTS hyperparameters for the first model configuration is:</p> <section class="relative block my-4"><ul class="flex flex-col ms-16 ps-2 rounded gap-0.5 bg-gray-100 divide-y divide-gray-200"><li class="flex items-center justify-left"><div class="flex-none w-64 min-w-64">horizon length</div> <div class="flex-none w-auto relative"><span class="rounded-0.5 p-1 font-mono">100</span></div> </li><li class="flex items-center justify-left"><div class="flex-none w-64 min-w-64">lookback window length</div> <div class="flex-none w-auto relative"><span class="rounded-0.5 p-1 font-mono">500</span></div> </li><li class="flex items-center justify-left"><div class="flex-none w-64 min-w-64">dt</div> <div class="flex-none w-auto relative"><span class="rounded-0.5 p-1 font-mono">0.015008</span></div> </li><li class="flex items-center justify-left"><div class="flex-none w-64 min-w-64">number of stacks</div> <div class="flex-none w-auto relative"><span class="rounded-0.5 p-1 font-mono">3</span></div> </li><li class="flex items-center justify-left"><div class="flex-none w-64 min-w-64">blocks per stack</div> <div class="flex-none w-auto relative"><span class="rounded-0.5 p-1 font-mono">1</span></div> </li><li class="flex items-center justify-left"><div class="flex-none w-64 min-w-64">mlp layers per block</div> <div class="flex-none w-auto relative"><span class="rounded-0.5 p-1 font-mono">4</span></div> </li><li class="flex items-center justify-left"><div class="flex-none w-64 min-w-64">mlp layer size</div> <div class="flex-none w-auto relative"><span class="rounded-0.5 p-1 font-mono">1024</span></div> </li><li class="flex items-center justify-left"><div class="flex-none w-64 min-w-64">activation function</div> <div class="flex-none w-auto relative"><span class="rounded-0.5 p-1 font-mono">ReLU</span></div> </li><li class="flex items-center justify-left"><div class="flex-none w-64 min-w-64">max pooling factors</div> <div class="flex-none w-auto relative"><span class="rounded-0.5 p-1 font-mono">2, 2, 2</span></div> </li><li class="flex items-center justify-left"><div class="flex-none w-64 min-w-64">frequency downsampling factors</div> <div class="flex-none w-auto relative"><span class="rounded-0.5 p-1 font-mono">24, 12, 1</span></div> </li><li class="flex items-center justify-left"><div class="flex-none w-64 min-w-64">batch size</div> <div class="flex-none w-auto relative"><span class="rounded-0.5 p-1 font-mono">512</span></div> </li><li class="flex items-center justify-left"><div class="flex-none w-64 min-w-64"># training steps</div> <div class="flex-none w-auto relative"><span class="rounded-0.5 p-1 font-mono">10000</span></div> </li><li class="flex items-center justify-left"><div class="flex-none w-64 min-w-64">learning rate</div> <div class="flex-none w-auto relative"><span class="rounded-0.5 p-1 font-mono">1e-3</span></div> </li><li class="flex items-center justify-left"><div class="flex-none w-64 min-w-64">learning rate schedule</div> <div class="flex-none w-auto relative"><span class="rounded-0.5 p-1 font-mono">halve every 3,333 steps</span></div> </li><li class="flex items-center justify-left"><div class="flex-none w-64 min-w-64">total trainable parameters</div> <div class="flex-none w-auto relative"><span class="rounded-0.5 p-1 font-mono">~20 million</span></div> </li></ul></section> <p class="my-2 indent-0 ">The model is optimized with MAE loss, consistent with the default loss from [<a href="https://arxiv.org/abs/2201.12886" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">4</a>]. For evaluation, I use the symmetric mean absolute percentage error (sMAPE) as defined in
		[<a href="https://link.aps.org/doi/10.1103/PhysRevResearch.5.043252" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">1</a>]:</p> <div>
\begin{align} 
\operatorname{\epsilon}(t) := \frac{200}{t} \sum_{t'=1}^t \frac{|\operatorname{\boldsymbol{y}}(t')-\operatorname{\boldsymbol{\hat{y}}}(t')|}{|\operatorname{\boldsymbol{y}}(t')| + |\operatorname{\boldsymbol{\hat{y}}}(t')|} \\
\end{align}</div> <p class="my-2 indent-8 ">In this formulation, sMAPE is bound to the interval [0, 200]. The distribution of average
		window errors and its CDF on the test set are shown below. Note that the left y axis is
		log-scaled.</p> <figure class="mb-6 self-center"><img class="m-auto" src="../Model1ErrDist.png" alt="" width="600" height="600"> <figcaption class="text-center text-xs mt-2 mx-36">Model 1 - sMAPE error distribution on the test set</figcaption></figure> <p class="my-2 indent-8 ">To gain a more intuitive understanding of the magnitude of these errors, we can plot
		individual window predictions against the references:</p> <figure class="mt-6 mb-6 self-center"><div class="flex justify-between"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="323" height="330" viewBox="200 100 376 230" xmlns="http://www.w3.org/2000/svg" version="1.1"><metadata><rdf:RDF xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"><cc:Work><dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"></dc:type><dc:date>2024-02-22T08:09:56.757681</dc:date><dc:format>image/svg+xml</dc:format><dc:creator><cc:Agent><dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title></cc:Agent></dc:creator></cc:Work></rdf:RDF></metadata><defs><style type="text/css">* {
				stroke-linejoin: round;
				stroke-linecap: butt;
			}</style></defs><g id="figure_1"><g id="patch_1"><path d="M 0 447.12 
L 727.92 447.12 
L 727.92 0 
L 0 0 
z
" style="fill: #ffffff"></path></g><g id="patch_2"><path d="M 200.9178 397.9368 
L 545.2002 397.9368 
L 545.2002 53.6544 
L 200.9178 53.6544 
z
" style="fill: #ffffff"></path></g><g id="pane3d_1"><g id="patch_3"><path d="M 226.913495 313.047794 
L 340.606788 217.747822 
L 339.026342 80.308226 
L 219.89224 167.246867 
" style="fill: #f2f2f2; opacity: 0.5; stroke: #f2f2f2; stroke-linejoin: miter"></path></g></g><g id="pane3d_2"><g id="patch_4"><path d="M 340.606788 217.747822 
L 523.043956 270.775104 
L 529.554495 128.601559 
L 339.026342 80.308226 
" style="fill: #e6e6e6; opacity: 0.5; stroke: #e6e6e6; stroke-linejoin: miter"></path></g></g><g id="pane3d_3"><g id="patch_5"><path d="M 226.913495 313.047794 
L 420.305804 376.209721 
L 523.043956 270.775104 
L 340.606788 217.747822 
" style="fill: #ececec; opacity: 0.5; stroke: #ececec; stroke-linejoin: miter"></path></g></g><g id="axis3d_1"><g id="line2d_1"><path d="M 226.913495 313.047794 
L 420.305804 376.209721 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="Line3DCollection_1"><path d="M 250.067732 320.609967 
L 362.534433 224.121322 
L 361.883967 86.101967 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 275.455326 328.901555 
L 386.550452 231.101831 
L 386.931839 92.450873 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 301.20411 337.311108 
L 410.879696 238.173382 
L 412.320585 98.88618 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 327.321844 345.84116 
L 435.528333 245.337767 
L 438.057212 105.409664 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 353.816518 354.49432 
L 460.502694 252.596828 
L 464.148918 112.023152 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 380.696349 363.273273 
L 485.809279 259.952453 
L 490.603104 118.728517 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 407.9698 372.180782 
L 511.454761 267.406582 
L 517.427376 125.527687 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path></g><g id="xtick_1"><g id="line2d_2"><path d="M 251.047339 319.769531 
L 248.104299 322.294456 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_1"><g transform="translate(232.001547 343.966901)scale(0.1 -0.1)"><defs><path id="DejaVuSans-2212" d="M 678 2272 
L 4684 2272 
L 4684 1741 
L 678 1741 
L 678 2272 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-31" d="M 794 531 
L 1825 531 
L 1825 4091 
L 703 3866 
L 703 4441 
L 1819 4666 
L 2450 4666 
L 2450 531 
L 3481 531 
L 3481 0 
L 794 0 
L 794 531 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-35" d="M 691 4666 
L 3169 4666 
L 3169 4134 
L 1269 4134 
L 1269 2991 
Q 1406 3038 1543 3061 
Q 1681 3084 1819 3084 
Q 2600 3084 3056 2656 
Q 3513 2228 3513 1497 
Q 3513 744 3044 326 
Q 2575 -91 1722 -91 
Q 1428 -91 1123 -41 
Q 819 9 494 109 
L 494 744 
Q 775 591 1075 516 
Q 1375 441 1709 441 
Q 2250 441 2565 725 
Q 2881 1009 2881 1497 
Q 2881 1984 2565 2268 
Q 2250 2553 1709 2553 
Q 1456 2553 1204 2497 
Q 953 2441 691 2322 
L 691 4666 
z
" transform="scale(0.015625)"></path></defs><use xlink:href="#DejaVuSans-2212"></use><use xlink:href="#DejaVuSans-31" x="83.789062"></use><use xlink:href="#DejaVuSans-35" x="147.412109"></use></g></g></g><g id="xtick_2"><g id="line2d_3"><path d="M 276.423544 328.04921 
L 273.514693 330.609942 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_2"><g transform="translate(257.409551 352.394167)scale(0.1 -0.1)"><defs><path id="DejaVuSans-30" d="M 2034 4250 
Q 1547 4250 1301 3770 
Q 1056 3291 1056 2328 
Q 1056 1369 1301 889 
Q 1547 409 2034 409 
Q 2525 409 2770 889 
Q 3016 1369 3016 2328 
Q 3016 3291 2770 3770 
Q 2525 4250 2034 4250 
z
M 2034 4750 
Q 2819 4750 3233 4129 
Q 3647 3509 3647 2328 
Q 3647 1150 3233 529 
Q 2819 -91 2034 -91 
Q 1250 -91 836 529 
Q 422 1150 422 2328 
Q 422 3509 836 4129 
Q 1250 4750 2034 4750 
z
" transform="scale(0.015625)"></path></defs><use xlink:href="#DejaVuSans-2212"></use><use xlink:href="#DejaVuSans-31" x="83.789062"></use><use xlink:href="#DejaVuSans-30" x="147.412109"></use></g></g></g><g id="xtick_3"><g id="line2d_4"><path d="M 302.160514 336.446597 
L 299.287126 339.043904 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_3"><g transform="translate(286.361339 360.941678)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-2212"></use><use xlink:href="#DejaVuSans-35" x="83.789062"></use></g></g></g><g id="xtick_4"><g id="line2d_5"><path d="M 328.265995 344.964222 
L 325.42939 347.598892 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_4"><g transform="translate(316.69207 369.612026)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-30"></use></g></g></g><g id="xtick_5"><g id="line2d_6"><path d="M 354.747961 353.604685 
L 351.949505 356.277531 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_5"><g transform="translate(343.211349 378.407877)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-35"></use></g></g></g><g id="xtick_6"><g id="line2d_7"><path d="M 381.614615 362.370663 
L 378.855721 365.082521 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_6"><g transform="translate(366.936044 387.331977)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-31"></use><use xlink:href="#DejaVuSans-30" x="63.623047"></use></g></g></g><g id="xtick_7"><g id="line2d_8"><path d="M 408.874401 371.264911 
L 406.156532 374.01664 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_7"><g transform="translate(394.237175 396.387152)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-31"></use><use xlink:href="#DejaVuSans-35" x="63.623047"></use></g></g></g></g><g id="axis3d_2"><g id="line2d_9"><path d="M 523.043956 270.775104 
L 420.305804 376.209721 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="Line3DCollection_2"><path d="M 235.984544 155.503436 
L 242.220503 300.217156 
L 434.190807 361.960292 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 262.259007 136.32953 
L 267.246514 279.239858 
L 456.856351 338.699869 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 287.553322 117.870892 
L 291.378558 259.011899 
L 478.670538 316.313147 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 311.921329 100.08823 
L 314.663697 239.493835 
L 499.680452 294.751806 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 335.412997 82.94508 
L 337.145744 220.648937 
L 519.929768 273.971027 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path></g><g id="xtick_8"><g id="line2d_10"><path d="M 432.573534 361.440131 
L 437.429513 363.001952 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_8"><g transform="translate(436.447152 382.900597)scale(0.1 -0.1)"><defs><path id="DejaVuSans-32" d="M 1228 531 
L 3431 531 
L 3431 0 
L 469 0 
L 469 531 
Q 828 903 1448 1529 
Q 2069 2156 2228 2338 
Q 2531 2678 2651 2914 
Q 2772 3150 2772 3378 
Q 2772 3750 2511 3984 
Q 2250 4219 1831 4219 
Q 1534 4219 1204 4116 
Q 875 4013 500 3803 
L 500 4441 
Q 881 4594 1212 4672 
Q 1544 4750 1819 4750 
Q 2544 4750 2975 4387 
Q 3406 4025 3406 3419 
Q 3406 3131 3298 2873 
Q 3191 2616 2906 2266 
Q 2828 2175 2409 1742 
Q 1991 1309 1228 531 
z
" transform="scale(0.015625)"></path></defs><use xlink:href="#DejaVuSans-2212"></use><use xlink:href="#DejaVuSans-32" x="83.789062"></use><use xlink:href="#DejaVuSans-30" x="147.412109"></use></g></g></g><g id="xtick_9"><g id="line2d_11"><path d="M 455.260504 338.199425 
L 460.05207 339.702019 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_9"><g transform="translate(458.877652 359.374193)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-2212"></use><use xlink:href="#DejaVuSans-31" x="83.789062"></use><use xlink:href="#DejaVuSans-30" x="147.412109"></use></g></g></g><g id="xtick_10"><g id="line2d_12"><path d="M 477.095663 315.83132 
L 481.824184 317.277992 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_10"><g transform="translate(487.836344 336.731872)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-30"></use></g></g></g><g id="xtick_11"><g id="line2d_13"><path d="M 498.126102 294.287577 
L 502.792927 295.681392 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_11"><g transform="translate(505.446429 314.92472)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-31"></use><use xlink:href="#DejaVuSans-30" x="63.623047"></use></g></g></g><g id="xtick_12"><g id="line2d_14"><path d="M 518.395502 273.523448 
L 523.001958 274.867252 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_12"><g transform="translate(525.484756 293.907364)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-32"></use><use xlink:href="#DejaVuSans-30" x="63.623047"></use></g></g></g></g><g id="axis3d_3"><g id="line2d_15"><path d="M 523.043956 270.775104 
L 529.554495 128.601559 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="Line3DCollection_3"><path d="M 523.708222 256.269223 
L 340.44523 203.698337 
L 226.198205 298.194321 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 524.536119 238.190076 
L 340.243973 186.19649 
L 225.306371 279.67481 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 525.373458 219.904719 
L 340.04053 168.504577 
L 224.403976 260.935989 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 526.220403 201.409603 
L 339.834865 150.619487 
L 223.490831 241.97394 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 527.07712 182.701098 
L 339.626943 132.538037 
L 222.566742 222.78465 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 527.943779 163.77549 
L 339.416726 114.256977 
L 221.631513 203.36401 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 528.820553 144.628977 
L 339.204174 95.772982 
L 220.68494 183.707811 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path></g><g id="xtick_13"><g id="line2d_16"><path d="M 522.169812 255.827914 
L 526.788718 257.152895 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_13"><g transform="translate(535.688516 261.282795)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-31"></use><use xlink:href="#DejaVuSans-30" x="63.623047"></use></g></g></g><g id="xtick_14"><g id="line2d_17"><path d="M 522.988657 237.753497 
L 527.63476 239.064283 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_14"><g transform="translate(536.618245 243.23138)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-31"></use><use xlink:href="#DejaVuSans-35" x="63.623047"></use></g></g></g><g id="xtick_15"><g id="line2d_18"><path d="M 523.816838 219.473006 
L 528.49046 220.769186 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_15"><g transform="translate(537.558553 224.974556)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-32"></use><use xlink:href="#DejaVuSans-30" x="63.623047"></use></g></g></g><g id="xtick_16"><g id="line2d_19"><path d="M 524.654516 200.982898 
L 529.355984 202.264049 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_16"><g transform="translate(538.509623 206.508797)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-32"></use><use xlink:href="#DejaVuSans-35" x="63.623047"></use></g></g></g><g id="xtick_17"><g id="line2d_20"><path d="M 525.501855 182.279545 
L 530.231502 183.545234 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_17"><g transform="translate(539.471639 187.830496)scale(0.1 -0.1)"><defs><path id="DejaVuSans-33" d="M 2597 2516 
Q 3050 2419 3304 2112 
Q 3559 1806 3559 1356 
Q 3559 666 3084 287 
Q 2609 -91 1734 -91 
Q 1441 -91 1130 -33 
Q 819 25 488 141 
L 488 750 
Q 750 597 1062 519 
Q 1375 441 1716 441 
Q 2309 441 2620 675 
Q 2931 909 2931 1356 
Q 2931 1769 2642 2001 
Q 2353 2234 1838 2234 
L 1294 2234 
L 1294 2753 
L 1863 2753 
Q 2328 2753 2575 2939 
Q 2822 3125 2822 3475 
Q 2822 3834 2567 4026 
Q 2313 4219 1838 4219 
Q 1578 4219 1281 4162 
Q 984 4106 628 3988 
L 628 4550 
Q 988 4650 1302 4700 
Q 1616 4750 1894 4750 
Q 2613 4750 3031 4423 
Q 3450 4097 3450 3541 
Q 3450 3153 3228 2886 
Q 3006 2619 2597 2516 
z
" transform="scale(0.015625)"></path></defs><use xlink:href="#DejaVuSans-33"></use><use xlink:href="#DejaVuSans-30" x="63.623047"></use></g></g></g><g id="xtick_18"><g id="line2d_21"><path d="M 526.359022 163.359237 
L 531.117188 164.609017 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_18"><g transform="translate(540.444793 168.935962)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-33"></use><use xlink:href="#DejaVuSans-35" x="63.623047"></use></g></g></g><g id="xtick_19"><g id="line2d_22"><path d="M 527.226191 144.218178 
L 532.013221 145.45159 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_19"><g transform="translate(541.429278 149.821418)scale(0.1 -0.1)"><defs><path id="DejaVuSans-34" d="M 2419 4116 
L 825 1625 
L 2419 1625 
L 2419 4116 
z
M 2253 4666 
L 3047 4666 
L 3047 1625 
L 3713 1625 
L 3713 1100 
L 3047 1100 
L 3047 0 
L 2419 0 
L 2419 1100 
L 313 1100 
L 313 1709 
L 2253 4666 
z
" transform="scale(0.015625)"></path></defs><use xlink:href="#DejaVuSans-34"></use><use xlink:href="#DejaVuSans-30" x="63.623047"></use></g></g></g></g><g id="axes_1"><g id="line2d_23"><path d="M 423.472791 252.497348 
L 427.362383 252.04936 
L 431.731545 251.11679 
L 436.599515 249.619968 
L 441.986336 247.479122 
L 447.905901 244.615919 
L 454.357426 240.931827 
L 461.264117 236.353221 
L 468.510453 230.8323 
L 475.952512 224.319074 
L 483.298746 216.913107 
L 490.212354 208.777369 
L 496.261909 200.163977 
L 500.96169 191.555723 
L 503.840187 183.484107 
L 504.411766 176.619804 
L 502.500229 171.487762 
L 498.051092 168.522737 
L 491.288376 167.927102 
L 482.732276 169.46896 
L 472.981045 172.791412 
L 462.698871 177.336386 
L 452.480804 182.541234 
L 442.774091 187.948012 
L 433.890569 193.220687 
L 425.984634 198.182445 
L 419.112408 202.755997 
L 413.24628 206.947431 
L 408.313756 210.800653 
L 404.216504 214.376623 
L 400.84749 217.735844 
L 398.100509 220.929918 
L 395.874812 224.000067 
L 394.081807 226.973954 
L 392.64039 229.871935 
L 391.484527 232.703861 
L 390.554588 235.47597 
L 389.802826 238.18963 
L 389.190146 240.84393 
L 388.681397 243.437298 
L 388.250572 245.967447 
L 387.875281 248.432275 
L 387.536108 250.829976 
L 387.218237 253.15977 
L 386.908165 255.421252 
L 386.594274 257.614766 
L 386.266295 259.741568 
L 385.91435 261.803201 
L 385.52926 263.801822 
L 385.100977 265.740435 
L 384.618619 267.622092 
L 384.072861 269.450127 
L 383.452019 271.228355 
L 382.740237 272.960892 
L 381.921647 274.651851 
L 380.977122 276.304941 
L 379.892031 277.925469 
L 378.638783 279.516418 
L 377.186059 281.080137 
L 375.502408 282.619026 
L 373.548163 284.130983 
L 371.290055 285.62307 
L 368.668198 287.080588 
L 365.621741 288.488613 
L 362.088561 289.828827 
L 357.996509 291.077035 
L 353.262294 292.175944 
L 347.800889 293.045664 
L 341.523337 293.591998 
L 334.342445 293.667461 
L 326.212336 293.041562 
L 317.115475 291.458171 
L 307.045614 288.564183 
L 296.242292 283.900739 
L 284.998456 276.994429 
L 273.837507 267.330942 
L 263.589899 254.605073 
L 255.280773 238.675544 
L 250.048272 220.128047 
L 248.936452 200.042269 
L 252.557921 180.204089 
L 260.836627 162.617938 
L 273.025034 149.119207 
L 287.800446 140.629344 
L 303.743972 137.29557 
L 319.595883 138.393601 
L 334.468318 142.800073 
L 347.852612 149.333675 
L 359.546641 156.978144 
L 369.55855 164.994383 
L 378.00822 172.869597 
L 385.080572 180.35085 
L 390.967607 187.270199 
L 395.866131 193.587573 
L 399.96125 199.300404 
L 403.417765 204.438797 
L 406.380334 209.042133 
L 408.9821 213.152324 
L 411.329116 216.80682 
L 413.51758 220.039013 
" clip-path="url(#pf0fa2af44b)" style="fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square"></path></g><g id="line2d_24"><path d="M 424.41975 252.585993 
L 428.291599 252.298412 
L 432.755408 250.756996 
L 438.155992 249.002391 
L 442.634021 246.842964 
L 448.997119 243.618267 
L 455.29354 240.362158 
L 461.965958 235.596079 
L 469.055952 230.228826 
L 476.389137 224.172848 
L 483.369551 216.634405 
L 490.221961 209.11121 
L 496.215717 201.178024 
L 499.998708 192.748023 
L 502.792413 184.979213 
L 502.998073 178.37378 
L 500.84022 173.258649 
L 496.229778 170.145715 
L 490.378403 169.634777 
L 481.661273 170.342021 
L 472.204582 174.145375 
L 461.704712 178.599712 
L 451.927526 183.853132 
L 442.648673 189.341228 
L 434.241596 194.854644 
L 426.196016 199.423694 
L 420.12909 203.772865 
L 414.603124 207.527654 
L 409.38157 212.122409 
L 405.800288 215.37383 
L 401.945007 217.955477 
L 399.482797 221.603822 
L 397.085731 224.210506 
L 395.201361 227.485803 
L 393.97247 230.659592 
L 392.54056 233.533292 
L 392.034656 236.554875 
L 391.222327 239.391334 
L 390.117031 241.839857 
L 389.573585 244.546643 
L 389.051261 247.054656 
L 388.210818 249.222981 
L 387.696745 250.988296 
L 386.709314 253.500419 
L 386.098944 256.030609 
L 385.89319 257.187651 
L 386.009884 259.179115 
L 386.032505 260.780742 
L 386.210045 262.295087 
L 386.254761 264.026306 
L 386.661657 265.940496 
L 385.994015 268.187428 
L 385.606839 269.816688 
L 385.654628 271.940789 
L 384.853979 273.891564 
L 383.535768 274.866059 
L 382.267986 277.320053 
L 380.851115 278.849063 
L 379.867338 281.491133 
L 378.140844 283.82931 
L 375.476199 285.505087 
L 373.342266 287.71366 
L 370.523977 289.465349 
L 367.236297 290.850972 
L 364.305572 292.799472 
L 359.945719 293.962108 
L 355.595775 294.833188 
L 349.806394 295.808275 
L 344.236409 296.865331 
L 336.784284 297.806878 
L 328.182441 297.277898 
L 318.356134 295.306664 
L 309.428485 292.403396 
L 298.802014 286.542909 
L 288.783417 278.689759 
L 279.31906 266.320332 
L 271.608439 253.676876 
L 265.626844 237.264481 
L 263.416213 219.688867 
L 263.483436 203.203182 
L 266.851747 186.035303 
L 273.878035 171.637928 
L 283.879836 161.255067 
L 295.7045 154.095131 
L 307.790234 150.663083 
L 321.422884 149.970412 
L 335.408455 151.38065 
L 348.056191 155.959343 
L 359.494653 160.87298 
L 370.573383 166.952191 
L 379.054583 173.03563 
L 387.824864 179.533155 
L 394.105078 185.146657 
L 399.067955 191.999807 
L 404.035837 197.912963 
L 407.131374 203.664831 
L 409.738266 208.489677 
L 412.524346 213.880357 
L 414.114895 218.398141 
L 416.507315 221.454496 
" clip-path="url(#pf0fa2af44b)" style="fill: none; stroke: #ff7f0e; stroke-opacity: 0.6; stroke-width: 1.5; stroke-linecap: square"></path></g><g id="text_20"><g transform="translate(315.714 47.6544)scale(0.12 -0.12)"><defs><path id="DejaVuSans-73" d="M 2834 3397 
L 2834 2853 
Q 2591 2978 2328 3040 
Q 2066 3103 1784 3103 
Q 1356 3103 1142 2972 
Q 928 2841 928 2578 
Q 928 2378 1081 2264 
Q 1234 2150 1697 2047 
L 1894 2003 
Q 2506 1872 2764 1633 
Q 3022 1394 3022 966 
Q 3022 478 2636 193 
Q 2250 -91 1575 -91 
Q 1294 -91 989 -36 
Q 684 19 347 128 
L 347 722 
Q 666 556 975 473 
Q 1284 391 1588 391 
Q 1994 391 2212 530 
Q 2431 669 2431 922 
Q 2431 1156 2273 1281 
Q 2116 1406 1581 1522 
L 1381 1569 
Q 847 1681 609 1914 
Q 372 2147 372 2553 
Q 372 3047 722 3315 
Q 1072 3584 1716 3584 
Q 2034 3584 2315 3537 
Q 2597 3491 2834 3397 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-4d" d="M 628 4666 
L 1569 4666 
L 2759 1491 
L 3956 4666 
L 4897 4666 
L 4897 0 
L 4281 0 
L 4281 4097 
L 3078 897 
L 2444 897 
L 1241 4097 
L 1241 0 
L 628 0 
L 628 4666 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-41" d="M 2188 4044 
L 1331 1722 
L 3047 1722 
L 2188 4044 
z
M 1831 4666 
L 2547 4666 
L 4325 0 
L 3669 0 
L 3244 1197 
L 1141 1197 
L 716 0 
L 50 0 
L 1831 4666 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-50" d="M 1259 4147 
L 1259 2394 
L 2053 2394 
Q 2494 2394 2734 2622 
Q 2975 2850 2975 3272 
Q 2975 3691 2734 3919 
Q 2494 4147 2053 4147 
L 1259 4147 
z
M 628 4666 
L 2053 4666 
Q 2838 4666 3239 4311 
Q 3641 3956 3641 3272 
Q 3641 2581 3239 2228 
Q 2838 1875 2053 1875 
L 1259 1875 
L 1259 0 
L 628 0 
L 628 4666 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-45" d="M 628 4666 
L 3578 4666 
L 3578 4134 
L 1259 4134 
L 1259 2753 
L 3481 2753 
L 3481 2222 
L 1259 2222 
L 1259 531 
L 3634 531 
L 3634 0 
L 628 0 
L 628 4666 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-20" transform="scale(0.015625)"></path><path id="DejaVuSans-72" d="M 2631 2963 
Q 2534 3019 2420 3045 
Q 2306 3072 2169 3072 
Q 1681 3072 1420 2755 
Q 1159 2438 1159 1844 
L 1159 0 
L 581 0 
L 581 3500 
L 1159 3500 
L 1159 2956 
Q 1341 3275 1631 3429 
Q 1922 3584 2338 3584 
Q 2397 3584 2469 3576 
Q 2541 3569 2628 3553 
L 2631 2963 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-6f" d="M 1959 3097 
Q 1497 3097 1228 2736 
Q 959 2375 959 1747 
Q 959 1119 1226 758 
Q 1494 397 1959 397 
Q 2419 397 2687 759 
Q 2956 1122 2956 1747 
Q 2956 2369 2687 2733 
Q 2419 3097 1959 3097 
z
M 1959 3584 
Q 2709 3584 3137 3096 
Q 3566 2609 3566 1747 
Q 3566 888 3137 398 
Q 2709 -91 1959 -91 
Q 1206 -91 779 398 
Q 353 888 353 1747 
Q 353 2609 779 3096 
Q 1206 3584 1959 3584 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-3a" d="M 750 794 
L 1409 794 
L 1409 0 
L 750 0 
L 750 794 
z
M 750 3309 
L 1409 3309 
L 1409 2516 
L 750 2516 
L 750 3309 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-2e" d="M 684 794 
L 1344 794 
L 1344 0 
L 684 0 
L 684 794 
z
" transform="scale(0.015625)"></path></defs><use xlink:href="#DejaVuSans-73"></use><use xlink:href="#DejaVuSans-4d" x="52.099609"></use><use xlink:href="#DejaVuSans-41" x="138.378906"></use><use xlink:href="#DejaVuSans-50" x="206.787109"></use><use xlink:href="#DejaVuSans-45" x="267.089844"></use><use xlink:href="#DejaVuSans-20" x="330.273438"></use><use xlink:href="#DejaVuSans-45" x="362.060547"></use><use xlink:href="#DejaVuSans-72" x="425.244141"></use><use xlink:href="#DejaVuSans-72" x="464.607422"></use><use xlink:href="#DejaVuSans-6f" x="503.470703"></use><use xlink:href="#DejaVuSans-72" x="564.652344"></use><use xlink:href="#DejaVuSans-3a" x="604.015625"></use><use xlink:href="#DejaVuSans-20" x="637.707031"></use><use xlink:href="#DejaVuSans-31" x="669.494141"></use><use xlink:href="#DejaVuSans-33" x="733.117188"></use><use xlink:href="#DejaVuSans-2e" x="796.740234"></use><use xlink:href="#DejaVuSans-30" x="828.527344"></use><use xlink:href="#DejaVuSans-30" x="892.150391"></use></g></g><g id="legend_1"><g id="patch_6"><path d="M 456.033012 91.01065 
L 538.2002 91.01065 
Q 540.2002 91.01065 540.2002 89.01065 
L 540.2002 60.6544 
Q 540.2002 58.6544 538.2002 58.6544 
L 456.033012 58.6544 
Q 454.033012 58.6544 454.033012 60.6544 
L 454.033012 89.01065 
Q 454.033012 91.01065 456.033012 91.01065 
z
" style="fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter"></path></g><g id="line2d_25"><path d="M 458.033012 66.752837 
L 468.033012 66.752837 
L 478.033012 66.752837 
" style="fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square"></path></g><g id="text_21"><g transform="translate(486.033012 70.252837)scale(0.1 -0.1)"><defs><path id="DejaVuSans-65" d="M 3597 1894 
L 3597 1613 
L 953 1613 
Q 991 1019 1311 708 
Q 1631 397 2203 397 
Q 2534 397 2845 478 
Q 3156 559 3463 722 
L 3463 178 
Q 3153 47 2828 -22 
Q 2503 -91 2169 -91 
Q 1331 -91 842 396 
Q 353 884 353 1716 
Q 353 2575 817 3079 
Q 1281 3584 2069 3584 
Q 2775 3584 3186 3129 
Q 3597 2675 3597 1894 
z
M 3022 2063 
Q 3016 2534 2758 2815 
Q 2500 3097 2075 3097 
Q 1594 3097 1305 2825 
Q 1016 2553 972 2059 
L 3022 2063 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-66" d="M 2375 4863 
L 2375 4384 
L 1825 4384 
Q 1516 4384 1395 4259 
Q 1275 4134 1275 3809 
L 1275 3500 
L 2222 3500 
L 2222 3053 
L 1275 3053 
L 1275 0 
L 697 0 
L 697 3053 
L 147 3053 
L 147 3500 
L 697 3500 
L 697 3744 
Q 697 4328 969 4595 
Q 1241 4863 1831 4863 
L 2375 4863 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-6e" d="M 3513 2113 
L 3513 0 
L 2938 0 
L 2938 2094 
Q 2938 2591 2744 2837 
Q 2550 3084 2163 3084 
Q 1697 3084 1428 2787 
Q 1159 2491 1159 1978 
L 1159 0 
L 581 0 
L 581 3500 
L 1159 3500 
L 1159 2956 
Q 1366 3272 1645 3428 
Q 1925 3584 2291 3584 
Q 2894 3584 3203 3211 
Q 3513 2838 3513 2113 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-63" d="M 3122 3366 
L 3122 2828 
Q 2878 2963 2633 3030 
Q 2388 3097 2138 3097 
Q 1578 3097 1268 2742 
Q 959 2388 959 1747 
Q 959 1106 1268 751 
Q 1578 397 2138 397 
Q 2388 397 2633 464 
Q 2878 531 3122 666 
L 3122 134 
Q 2881 22 2623 -34 
Q 2366 -91 2075 -91 
Q 1284 -91 818 406 
Q 353 903 353 1747 
Q 353 2603 823 3093 
Q 1294 3584 2113 3584 
Q 2378 3584 2631 3529 
Q 2884 3475 3122 3366 
z
" transform="scale(0.015625)"></path></defs><use xlink:href="#DejaVuSans-72"></use><use xlink:href="#DejaVuSans-65" x="38.863281"></use><use xlink:href="#DejaVuSans-66" x="100.386719"></use><use xlink:href="#DejaVuSans-65" x="135.591797"></use><use xlink:href="#DejaVuSans-72" x="197.115234"></use><use xlink:href="#DejaVuSans-65" x="235.978516"></use><use xlink:href="#DejaVuSans-6e" x="297.501953"></use><use xlink:href="#DejaVuSans-63" x="360.880859"></use><use xlink:href="#DejaVuSans-65" x="415.861328"></use></g></g><g id="line2d_26"><path d="M 458.033012 81.430963 
L 468.033012 81.430963 
L 478.033012 81.430963 
" style="fill: none; stroke: #ff7f0e; stroke-opacity: 0.6; stroke-width: 1.5; stroke-linecap: square"></path></g><g id="text_22"><g transform="translate(486.033012 84.930963)scale(0.1 -0.1)"><defs><path id="DejaVuSans-70" d="M 1159 525 
L 1159 -1331 
L 581 -1331 
L 581 3500 
L 1159 3500 
L 1159 2969 
Q 1341 3281 1617 3432 
Q 1894 3584 2278 3584 
Q 2916 3584 3314 3078 
Q 3713 2572 3713 1747 
Q 3713 922 3314 415 
Q 2916 -91 2278 -91 
Q 1894 -91 1617 61 
Q 1341 213 1159 525 
z
M 3116 1747 
Q 3116 2381 2855 2742 
Q 2594 3103 2138 3103 
Q 1681 3103 1420 2742 
Q 1159 2381 1159 1747 
Q 1159 1113 1420 752 
Q 1681 391 2138 391 
Q 2594 391 2855 752 
Q 3116 1113 3116 1747 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-64" d="M 2906 2969 
L 2906 4863 
L 3481 4863 
L 3481 0 
L 2906 0 
L 2906 525 
Q 2725 213 2448 61 
Q 2172 -91 1784 -91 
Q 1150 -91 751 415 
Q 353 922 353 1747 
Q 353 2572 751 3078 
Q 1150 3584 1784 3584 
Q 2172 3584 2448 3432 
Q 2725 3281 2906 2969 
z
M 947 1747 
Q 947 1113 1208 752 
Q 1469 391 1925 391 
Q 2381 391 2643 752 
Q 2906 1113 2906 1747 
Q 2906 2381 2643 2742 
Q 2381 3103 1925 3103 
Q 1469 3103 1208 2742 
Q 947 2381 947 1747 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-69" d="M 603 3500 
L 1178 3500 
L 1178 0 
L 603 0 
L 603 3500 
z
M 603 4863 
L 1178 4863 
L 1178 4134 
L 603 4134 
L 603 4863 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-74" d="M 1172 4494 
L 1172 3500 
L 2356 3500 
L 2356 3053 
L 1172 3053 
L 1172 1153 
Q 1172 725 1289 603 
Q 1406 481 1766 481 
L 2356 481 
L 2356 0 
L 1766 0 
Q 1100 0 847 248 
Q 594 497 594 1153 
L 594 3053 
L 172 3053 
L 172 3500 
L 594 3500 
L 594 4494 
L 1172 4494 
z
" transform="scale(0.015625)"></path></defs><use xlink:href="#DejaVuSans-70"></use><use xlink:href="#DejaVuSans-72" x="63.476562"></use><use xlink:href="#DejaVuSans-65" x="102.339844"></use><use xlink:href="#DejaVuSans-64" x="163.863281"></use><use xlink:href="#DejaVuSans-69" x="227.339844"></use><use xlink:href="#DejaVuSans-63" x="255.123047"></use><use xlink:href="#DejaVuSans-74" x="310.103516"></use><use xlink:href="#DejaVuSans-69" x="349.3125"></use><use xlink:href="#DejaVuSans-6f" x="377.095703"></use><use xlink:href="#DejaVuSans-6e" x="438.277344"></use></g></g></g></g></g><defs><clipPath id="pf0fa2af44b"><rect x="200.9178" y="53.6544" width="344.2824" height="344.2824"></rect></clipPath></defs></svg> <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="323" height="330" viewBox="200 100 376 230" xmlns="http://www.w3.org/2000/svg" version="1.1"><metadata><rdf:RDF xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"><cc:Work><dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"></dc:type><dc:date>2024-02-22T08:11:23.377047</dc:date><dc:format>image/svg+xml</dc:format><dc:creator><cc:Agent><dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title></cc:Agent></dc:creator></cc:Work></rdf:RDF></metadata><defs><style type="text/css">* {
				stroke-linejoin: round;
				stroke-linecap: butt;
			}</style></defs><g id="figure_1"><g id="patch_1"><path d="M 0 447.12 
L 727.92 447.12 
L 727.92 0 
L 0 0 
z
" style="fill: #ffffff"></path></g><g id="patch_2"><path d="M 200.9178 397.9368 
L 545.2002 397.9368 
L 545.2002 53.6544 
L 200.9178 53.6544 
z
" style="fill: #ffffff"></path></g><g id="pane3d_1"><g id="patch_3"><path d="M 225.132366 297.754882 
L 395.743557 269.783343 
L 396.019699 118.444731 
L 222.628608 136.047513 
" style="fill: #f2f2f2; opacity: 0.5; stroke: #f2f2f2; stroke-linejoin: miter"></path></g></g><g id="pane3d_2"><g id="patch_4"><path d="M 395.743557 269.783343 
L 533.466139 306.60739 
L 536.076092 141.626406 
L 396.019699 118.444731 
" style="fill: #e6e6e6; opacity: 0.5; stroke: #e6e6e6; stroke-linejoin: miter"></path></g></g><g id="pane3d_3"><g id="patch_5"><path d="M 225.132366 297.754882 
L 356.482947 340.222611 
L 533.466139 306.60739 
L 395.743557 269.783343 
" style="fill: #ececec; opacity: 0.5; stroke: #ececec; stroke-linejoin: miter"></path></g></g><g id="axis3d_1"><g id="line2d_1"><path d="M 225.132366 297.754882 
L 356.482947 340.222611 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="Line3DCollection_1"><path d="M 244.249002 303.935594 
L 415.899914 275.172718 
L 416.492783 121.833369 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 262.597154 309.867843 
L 435.209827 280.335772 
L 436.114103 125.081025 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 281.45681 315.96547 
L 455.021243 285.632917 
L 456.253133 128.414372 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 300.849661 322.235486 
L 475.353956 291.069446 
L 476.930637 131.836844 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 320.798645 328.68531 
L 496.228815 296.650933 
L 498.168505 135.352066 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 341.32803 335.322786 
L 517.667798 302.383255 
L 519.989827 138.96386 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path></g><g id="xtick_1"><g id="line2d_2"><path d="M 245.719436 303.689199 
L 241.303088 304.42923 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_1"><g transform="translate(222.000848 323.899256)scale(0.1 -0.1)"><defs><path id="DejaVuSans-2212" d="M 678 2272 
L 4684 2272 
L 4684 1741 
L 678 1741 
L 678 2272 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-31" d="M 794 531 
L 1825 531 
L 1825 4091 
L 703 3866 
L 703 4441 
L 1819 4666 
L 2450 4666 
L 2450 531 
L 3481 531 
L 3481 0 
L 794 0 
L 794 531 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-35" d="M 691 4666 
L 3169 4666 
L 3169 4134 
L 1269 4134 
L 1269 2991 
Q 1406 3038 1543 3061 
Q 1681 3084 1819 3084 
Q 2600 3084 3056 2656 
Q 3513 2228 3513 1497 
Q 3513 744 3044 326 
Q 2575 -91 1722 -91 
Q 1428 -91 1123 -41 
Q 819 9 494 109 
L 494 744 
Q 775 591 1075 516 
Q 1375 441 1709 441 
Q 2250 441 2565 725 
Q 2881 1009 2881 1497 
Q 2881 1984 2565 2268 
Q 2250 2553 1709 2553 
Q 1456 2553 1204 2497 
Q 953 2441 691 2322 
L 691 4666 
z
" transform="scale(0.015625)"></path></defs><use xlink:href="#DejaVuSans-2212"></use><use xlink:href="#DejaVuSans-31" x="83.789062"></use><use xlink:href="#DejaVuSans-35" x="147.412109"></use></g></g></g><g id="xtick_2"><g id="line2d_3"><path d="M 264.07717 309.614629 
L 259.631973 310.375152 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_2"><g transform="translate(240.253525 330.023405)scale(0.1 -0.1)"><defs><path id="DejaVuSans-30" d="M 2034 4250 
Q 1547 4250 1301 3770 
Q 1056 3291 1056 2328 
Q 1056 1369 1301 889 
Q 1547 409 2034 409 
Q 2525 409 2770 889 
Q 3016 1369 3016 2328 
Q 3016 3291 2770 3770 
Q 2525 4250 2034 4250 
z
M 2034 4750 
Q 2819 4750 3233 4129 
Q 3647 3509 3647 2328 
Q 3647 1150 3233 529 
Q 2819 -91 2034 -91 
Q 1250 -91 836 529 
Q 422 1150 422 2328 
Q 422 3509 836 4129 
Q 1250 4750 2034 4750 
z
" transform="scale(0.015625)"></path></defs><use xlink:href="#DejaVuSans-2212"></use><use xlink:href="#DejaVuSans-31" x="83.789062"></use><use xlink:href="#DejaVuSans-30" x="147.412109"></use></g></g></g><g id="xtick_3"><g id="line2d_4"><path d="M 282.946375 315.705149 
L 278.472425 316.487028 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_3"><g transform="translate(262.198148 336.318903)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-2212"></use><use xlink:href="#DejaVuSans-35" x="83.789062"></use></g></g></g><g id="xtick_4"><g id="line2d_5"><path d="M 302.348728 321.967757 
L 297.846166 322.771903 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_4"><g transform="translate(285.683796 342.793044)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-30"></use></g></g></g><g id="xtick_5"><g id="line2d_6"><path d="M 322.307149 328.40985 
L 317.776162 329.237229 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_5"><g transform="translate(305.535023 349.453539)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-35"></use></g></g></g><g id="xtick_6"><g id="line2d_7"><path d="M 342.845891 335.039256 
L 338.286719 335.89089 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_6"><g transform="translate(322.784752 356.308554)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-31"></use><use xlink:href="#DejaVuSans-30" x="63.623047"></use></g></g></g></g><g id="axis3d_2"><g id="line2d_8"><path d="M 533.466139 306.60739 
L 356.482947 340.222611 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="Line3DCollection_2"><path d="M 232.355546 135.060028 
L 234.693617 296.187325 
L 366.462744 338.327103 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 253.652477 132.897949 
L 255.63182 292.754527 
L 388.291898 334.180993 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 274.601645 130.771175 
L 276.233528 289.376897 
L 409.735969 330.108023 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 295.211498 128.678849 
L 296.506788 286.053115 
L 430.805059 326.106275 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 315.490214 126.62014 
L 316.459392 282.781905 
L 451.508918 322.173897 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 335.445709 124.594244 
L 336.098889 279.562028 
L 471.856961 318.309101 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 355.085652 122.600384 
L 355.432591 276.392287 
L 491.858282 314.510159 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 374.417466 120.637805 
L 374.467586 273.271518 
L 511.521669 310.775403 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path></g><g id="xtick_7"><g id="line2d_9"><path d="M 365.304688 337.956757 
L 368.784391 339.069566 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_7"><g transform="translate(365.263338 360.101845)scale(0.1 -0.1)"><defs><path id="DejaVuSans-32" d="M 1228 531 
L 3431 531 
L 3431 0 
L 469 0 
L 469 531 
Q 828 903 1448 1529 
Q 2069 2156 2228 2338 
Q 2531 2678 2651 2914 
Q 2772 3150 2772 3378 
Q 2772 3750 2511 3984 
Q 2250 4219 1831 4219 
Q 1534 4219 1204 4116 
Q 875 4013 500 3803 
L 500 4441 
Q 881 4594 1212 4672 
Q 1544 4750 1819 4750 
Q 2544 4750 2975 4387 
Q 3406 4025 3406 3419 
Q 3406 3131 3298 2873 
Q 3191 2616 2906 2266 
Q 2828 2175 2409 1742 
Q 1991 1309 1228 531 
z
" transform="scale(0.015625)"></path></defs><use xlink:href="#DejaVuSans-2212"></use><use xlink:href="#DejaVuSans-32" x="83.789062"></use><use xlink:href="#DejaVuSans-35" x="147.412109"></use></g></g></g><g id="xtick_8"><g id="line2d_10"><path d="M 387.126942 333.817206 
L 390.627329 334.91029 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_8"><g transform="translate(387.122855 355.807265)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-2212"></use><use xlink:href="#DejaVuSans-32" x="83.789062"></use><use xlink:href="#DejaVuSans-30" x="147.412109"></use></g></g></g><g id="xtick_9"><g id="line2d_11"><path d="M 408.564536 329.750623 
L 412.084337 330.824502 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_9"><g transform="translate(408.594758 351.588836)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-2212"></use><use xlink:href="#DejaVuSans-31" x="83.789062"></use><use xlink:href="#DejaVuSans-35" x="147.412109"></use></g></g></g><g id="xtick_10"><g id="line2d_12"><path d="M 429.627552 325.755095 
L 433.165556 326.81027 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_10"><g transform="translate(429.689265 347.444552)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-2212"></use><use xlink:href="#DejaVuSans-31" x="83.789062"></use><use xlink:href="#DejaVuSans-30" x="147.412109"></use></g></g></g><g id="xtick_11"><g id="line2d_13"><path d="M 450.325722 321.828776 
L 453.880771 322.865732 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_11"><g transform="translate(453.597491 343.372474)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-2212"></use><use xlink:href="#DejaVuSans-35" x="83.789062"></use></g></g></g><g id="xtick_12"><g id="line2d_14"><path d="M 470.668444 317.969883 
L 474.239432 318.989088 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_12"><g transform="translate(478.1563 339.370732)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-30"></use></g></g></g><g id="xtick_13"><g id="line2d_15"><path d="M 490.664797 314.176695 
L 494.250666 315.178601 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_13"><g transform="translate(498.176452 335.437518)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-35"></use></g></g></g><g id="xtick_14"><g id="line2d_16"><path d="M 510.323552 310.447547 
L 513.923291 311.43259 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_14"><g transform="translate(514.675425 331.571088)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-31"></use><use xlink:href="#DejaVuSans-30" x="63.623047"></use></g></g></g></g><g id="axis3d_3"><g id="line2d_17"><path d="M 533.466139 306.60739 
L 536.076092 141.626406 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="Line3DCollection_3"><path d="M 533.570443 300.014077 
L 395.754607 263.726984 
L 225.032273 291.290277 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 533.873047 280.885804 
L 395.786661 246.160392 
L 224.741902 272.536403 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 534.176828 261.683109 
L 395.818828 228.531276 
L 224.450424 253.71106 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 534.481794 242.405559 
L 395.85111 210.839301 
L 224.157833 234.813838 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 534.787951 223.052715 
L 395.883507 193.084131 
L 223.864123 215.844324 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 535.095305 203.624134 
L 395.91602 175.265426 
L 223.569288 196.802103 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 535.403865 184.119372 
L 395.94865 157.382845 
L 223.27332 177.686756 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 535.713638 164.537979 
L 395.981397 139.436044 
L 222.976213 158.497862 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path></g><g id="xtick_15"><g id="line2d_18"><path d="M 532.366571 299.697096 
L 535.983554 300.649453 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_15"><g transform="translate(550.615919 308.184418)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-35"></use></g></g></g><g id="xtick_16"><g id="line2d_19"><path d="M 532.666614 280.582415 
L 536.291301 281.493936 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_16"><g transform="translate(547.777001 289.031623)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-31"></use><use xlink:href="#DejaVuSans-30" x="63.623047"></use></g></g></g><g id="xtick_17"><g id="line2d_20"><path d="M 532.967825 261.393421 
L 536.600246 262.263782 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_17"><g transform="translate(548.120668 269.804212)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-31"></use><use xlink:href="#DejaVuSans-35" x="63.623047"></use></g></g></g><g id="xtick_18"><g id="line2d_21"><path d="M 533.270208 242.129681 
L 536.910398 242.958553 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_18"><g transform="translate(548.465676 250.501748)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-32"></use><use xlink:href="#DejaVuSans-30" x="63.623047"></use></g></g></g><g id="xtick_19"><g id="line2d_22"><path d="M 533.573772 222.790756 
L 537.221763 223.577809 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_19"><g transform="translate(548.812033 231.12379)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-32"></use><use xlink:href="#DejaVuSans-35" x="63.623047"></use></g></g></g><g id="xtick_20"><g id="line2d_23"><path d="M 533.878522 203.376207 
L 537.534349 204.121106 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_20"><g transform="translate(549.159748 211.669896)scale(0.1 -0.1)"><defs><path id="DejaVuSans-33" d="M 2597 2516 
Q 3050 2419 3304 2112 
Q 3559 1806 3559 1356 
Q 3559 666 3084 287 
Q 2609 -91 1734 -91 
Q 1441 -91 1130 -33 
Q 819 25 488 141 
L 488 750 
Q 750 597 1062 519 
Q 1375 441 1716 441 
Q 2309 441 2620 675 
Q 2931 909 2931 1356 
Q 2931 1769 2642 2001 
Q 2353 2234 1838 2234 
L 1294 2234 
L 1294 2753 
L 1863 2753 
Q 2328 2753 2575 2939 
Q 2822 3125 2822 3475 
Q 2822 3834 2567 4026 
Q 2313 4219 1838 4219 
Q 1578 4219 1281 4162 
Q 984 4106 628 3988 
L 628 4550 
Q 988 4650 1302 4700 
Q 1616 4750 1894 4750 
Q 2613 4750 3031 4423 
Q 3450 4097 3450 3541 
Q 3450 3153 3228 2886 
Q 3006 2619 2597 2516 
z
" transform="scale(0.015625)"></path></defs><use xlink:href="#DejaVuSans-33"></use><use xlink:href="#DejaVuSans-30" x="63.623047"></use></g></g></g><g id="xtick_21"><g id="line2d_24"><path d="M 534.184467 183.885588 
L 537.848162 184.587996 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_21"><g transform="translate(549.508828 192.139618)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-33"></use><use xlink:href="#DejaVuSans-35" x="63.623047"></use></g></g></g><g id="xtick_22"><g id="line2d_25"><path d="M 534.491613 164.318451 
L 538.163209 164.978028 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_22"><g transform="translate(549.859281 172.532505)scale(0.1 -0.1)"><defs><path id="DejaVuSans-34" d="M 2419 4116 
L 825 1625 
L 2419 1625 
L 2419 4116 
z
M 2253 4666 
L 3047 4666 
L 3047 1625 
L 3713 1625 
L 3713 1100 
L 3047 1100 
L 3047 0 
L 2419 0 
L 2419 1100 
L 313 1100 
L 313 1709 
L 2253 4666 
z
" transform="scale(0.015625)"></path></defs><use xlink:href="#DejaVuSans-34"></use><use xlink:href="#DejaVuSans-30" x="63.623047"></use></g></g></g></g><g id="axes_1"><g id="line2d_26"><path d="M 331.652321 160.302933 
L 343.820515 161.119825 
L 355.410695 163.79061 
L 365.957847 167.853881 
L 375.217161 172.831354 
L 383.143372 178.343734 
L 389.754224 184.060543 
L 395.176898 189.785484 
L 399.553603 195.373946 
L 403.03984 200.745126 
L 405.783463 205.862098 
L 407.92022 210.710929 
L 409.566199 215.295235 
L 410.822346 219.626031 
L 411.769766 223.718873 
L 412.478391 227.590625 
L 412.999643 231.257537 
L 413.378865 234.735571 
L 413.648744 238.038869 
L 413.835202 241.180396 
L 413.959427 244.17219 
L 414.035056 247.024272 
L 414.073902 249.746239 
L 414.084431 252.346591 
L 414.071827 254.83259 
L 414.0404 257.211173 
L 413.99278 259.488482 
L 413.930059 261.669883 
L 413.85292 263.760534 
L 413.761162 265.76505 
L 413.653676 267.687553 
L 413.529066 269.532021 
L 413.385344 271.302081 
L 413.219665 273.001026 
L 413.028719 274.632025 
L 412.809206 276.198111 
L 412.555734 277.701899 
L 412.26271 279.145974 
L 411.924076 280.53282 
L 411.532586 281.864692 
L 411.078072 283.14348 
L 410.549731 284.370981 
L 409.936706 285.549012 
L 409.223955 286.678751 
L 408.392533 287.760793 
L 407.421829 288.795346 
L 406.291775 289.783037 
L 404.972045 290.721957 
L 403.427418 291.608961 
L 401.619034 292.439325 
L 399.508552 293.209996 
L 397.037283 293.907883 
L 394.141267 294.51727 
L 390.750464 295.0163 
L 386.790401 295.387505 
L 382.160023 295.57708 
L 376.754686 295.526558 
L 370.470789 295.156556 
L 363.171521 294.387903 
L 354.760624 293.036459 
L 345.145751 290.912452 
L 334.254356 287.78444 
L 322.123207 283.320916 
L 308.9455 277.144935 
L 295.014708 268.814466 
L 281.093587 257.94731 
L 268.163736 244.246362 
L 257.641232 227.727497 
L 251.176284 208.90268 
L 250.359276 188.932591 
L 256.213657 169.595148 
L 268.783567 152.972808 
L 286.880026 140.854956 
L 308.430946 134.263683 
L 331.059691 133.105954 
L 352.736141 136.464978 
L 372.13137 142.962252 
L 388.648967 151.217697 
L 402.244385 160.119956 
L 413.193072 168.9316 
L 421.905811 177.189094 
L 428.803667 184.729747 
L 434.280243 191.485303 
L 438.668856 197.493206 
L 442.245606 202.821446 
L 445.238843 207.549443 
L 447.821809 211.749457 
L 450.15005 215.488731 
L 452.333244 218.815319 
L 454.464696 221.768822 
L 456.62838 224.383114 
L 458.874823 226.671129 
L 461.250481 228.643852 
L 463.793871 230.306944 
L 466.538509 231.659483 
L 469.4916 232.68878 
L 472.660587 233.382316 
L 476.034359 233.729724 
L 479.635173 233.701297 
L 483.412935 233.280682 
" clip-path="url(#p4bc3fb7813)" style="fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square"></path></g><g id="line2d_27"><path d="M 334.926178 161.57787 
L 348.502299 161.851622 
L 360.20627 165.316674 
L 371.467966 169.864268 
L 381.151999 175.36752 
L 389.129717 180.514356 
L 395.191486 186.047529 
L 400.303177 191.504356 
L 403.697481 196.647994 
L 406.599292 202.097295 
L 408.995107 206.909117 
L 411.122256 212.103024 
L 412.042344 216.765529 
L 414.339557 221.693441 
L 414.405207 226.018017 
L 416.258551 230.293252 
L 415.551707 234.062285 
L 415.822943 238.070132 
L 415.159481 240.092534 
L 414.138868 243.06782 
L 413.497228 247.08532 
L 412.674014 248.555676 
L 413.475476 250.780595 
L 413.295336 253.868009 
L 412.958838 255.668634 
L 413.100478 257.866114 
L 413.313382 260.005763 
L 413.610672 262.665159 
L 414.053443 264.654304 
L 414.523371 266.573529 
L 414.169635 268.208209 
L 413.853338 269.98661 
L 413.926403 271.475578 
L 414.179293 273.357223 
L 413.842778 274.497715 
L 414.447991 275.730951 
L 413.086322 276.886602 
L 413.045005 278.822452 
L 412.806506 280.667198 
L 412.611401 281.620557 
L 411.372193 282.730884 
L 411.260814 284.313932 
L 410.32209 285.956027 
L 409.260151 287.061714 
L 407.57748 287.973634 
L 406.853267 289.319349 
L 404.216415 290.515771 
L 402.928804 291.442724 
L 400.125889 292.277145 
L 398.689224 293.723903 
L 396.009118 293.87017 
L 395.463828 293.529461 
L 393.8855 294.428489 
L 390.837725 294.748442 
L 387.145594 295.192739 
L 383.032692 295.186032 
L 374.442233 294.320211 
L 367.172719 292.677836 
L 359.615741 289.257144 
L 350.669685 284.567183 
L 343.879531 278.321213 
L 337.374659 268.662642 
L 331.582591 255.680276 
L 327.63241 242.686262 
L 326.727232 227.25932 
L 325.788752 211.318623 
L 329.904787 196.900638 
L 335.301354 181.891526 
L 342.229121 171.411272 
L 350.906972 163.1685 
L 361.642372 158.477356 
L 369.830528 155.546345 
L 377.872445 156.498556 
L 387.108063 160.418765 
L 395.313007 167.598737 
L 402.237443 172.837549 
L 408.621744 179.441097 
L 416.213297 185.96432 
L 420.688822 192.786099 
L 425.663024 198.253111 
L 429.392304 203.317259 
L 432.596003 206.768472 
L 434.322566 210.361837 
L 436.415666 212.987022 
L 439.820167 216.076963 
L 440.214723 218.9394 
L 441.701447 220.582827 
L 443.730392 223.949275 
L 446.594576 225.881042 
L 450.028385 227.755636 
L 452.692341 229.317925 
L 455.41905 231.052169 
L 457.66615 231.296757 
L 461.7537 231.01175 
L 464.901308 230.82714 
L 469.116069 230.913115 
L 469.943802 230.770496 
L 472.077551 230.90117 
L 473.5757 229.834041 
L 473.980718 228.506175 
" clip-path="url(#p4bc3fb7813)" style="fill: none; stroke: #ff7f0e; stroke-opacity: 0.6; stroke-width: 1.5; stroke-linecap: square"></path></g><g id="text_23"><g transform="translate(315.714 47.6544)scale(0.12 -0.12)"><defs><path id="DejaVuSans-73" d="M 2834 3397 
L 2834 2853 
Q 2591 2978 2328 3040 
Q 2066 3103 1784 3103 
Q 1356 3103 1142 2972 
Q 928 2841 928 2578 
Q 928 2378 1081 2264 
Q 1234 2150 1697 2047 
L 1894 2003 
Q 2506 1872 2764 1633 
Q 3022 1394 3022 966 
Q 3022 478 2636 193 
Q 2250 -91 1575 -91 
Q 1294 -91 989 -36 
Q 684 19 347 128 
L 347 722 
Q 666 556 975 473 
Q 1284 391 1588 391 
Q 1994 391 2212 530 
Q 2431 669 2431 922 
Q 2431 1156 2273 1281 
Q 2116 1406 1581 1522 
L 1381 1569 
Q 847 1681 609 1914 
Q 372 2147 372 2553 
Q 372 3047 722 3315 
Q 1072 3584 1716 3584 
Q 2034 3584 2315 3537 
Q 2597 3491 2834 3397 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-4d" d="M 628 4666 
L 1569 4666 
L 2759 1491 
L 3956 4666 
L 4897 4666 
L 4897 0 
L 4281 0 
L 4281 4097 
L 3078 897 
L 2444 897 
L 1241 4097 
L 1241 0 
L 628 0 
L 628 4666 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-41" d="M 2188 4044 
L 1331 1722 
L 3047 1722 
L 2188 4044 
z
M 1831 4666 
L 2547 4666 
L 4325 0 
L 3669 0 
L 3244 1197 
L 1141 1197 
L 716 0 
L 50 0 
L 1831 4666 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-50" d="M 1259 4147 
L 1259 2394 
L 2053 2394 
Q 2494 2394 2734 2622 
Q 2975 2850 2975 3272 
Q 2975 3691 2734 3919 
Q 2494 4147 2053 4147 
L 1259 4147 
z
M 628 4666 
L 2053 4666 
Q 2838 4666 3239 4311 
Q 3641 3956 3641 3272 
Q 3641 2581 3239 2228 
Q 2838 1875 2053 1875 
L 1259 1875 
L 1259 0 
L 628 0 
L 628 4666 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-45" d="M 628 4666 
L 3578 4666 
L 3578 4134 
L 1259 4134 
L 1259 2753 
L 3481 2753 
L 3481 2222 
L 1259 2222 
L 1259 531 
L 3634 531 
L 3634 0 
L 628 0 
L 628 4666 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-20" transform="scale(0.015625)"></path><path id="DejaVuSans-72" d="M 2631 2963 
Q 2534 3019 2420 3045 
Q 2306 3072 2169 3072 
Q 1681 3072 1420 2755 
Q 1159 2438 1159 1844 
L 1159 0 
L 581 0 
L 581 3500 
L 1159 3500 
L 1159 2956 
Q 1341 3275 1631 3429 
Q 1922 3584 2338 3584 
Q 2397 3584 2469 3576 
Q 2541 3569 2628 3553 
L 2631 2963 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-6f" d="M 1959 3097 
Q 1497 3097 1228 2736 
Q 959 2375 959 1747 
Q 959 1119 1226 758 
Q 1494 397 1959 397 
Q 2419 397 2687 759 
Q 2956 1122 2956 1747 
Q 2956 2369 2687 2733 
Q 2419 3097 1959 3097 
z
M 1959 3584 
Q 2709 3584 3137 3096 
Q 3566 2609 3566 1747 
Q 3566 888 3137 398 
Q 2709 -91 1959 -91 
Q 1206 -91 779 398 
Q 353 888 353 1747 
Q 353 2609 779 3096 
Q 1206 3584 1959 3584 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-3a" d="M 750 794 
L 1409 794 
L 1409 0 
L 750 0 
L 750 794 
z
M 750 3309 
L 1409 3309 
L 1409 2516 
L 750 2516 
L 750 3309 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-2e" d="M 684 794 
L 1344 794 
L 1344 0 
L 684 0 
L 684 794 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-39" d="M 703 97 
L 703 672 
Q 941 559 1184 500 
Q 1428 441 1663 441 
Q 2288 441 2617 861 
Q 2947 1281 2994 2138 
Q 2813 1869 2534 1725 
Q 2256 1581 1919 1581 
Q 1219 1581 811 2004 
Q 403 2428 403 3163 
Q 403 3881 828 4315 
Q 1253 4750 1959 4750 
Q 2769 4750 3195 4129 
Q 3622 3509 3622 2328 
Q 3622 1225 3098 567 
Q 2575 -91 1691 -91 
Q 1453 -91 1209 -44 
Q 966 3 703 97 
z
M 1959 2075 
Q 2384 2075 2632 2365 
Q 2881 2656 2881 3163 
Q 2881 3666 2632 3958 
Q 2384 4250 1959 4250 
Q 1534 4250 1286 3958 
Q 1038 3666 1038 3163 
Q 1038 2656 1286 2365 
Q 1534 2075 1959 2075 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-38" d="M 2034 2216 
Q 1584 2216 1326 1975 
Q 1069 1734 1069 1313 
Q 1069 891 1326 650 
Q 1584 409 2034 409 
Q 2484 409 2743 651 
Q 3003 894 3003 1313 
Q 3003 1734 2745 1975 
Q 2488 2216 2034 2216 
z
M 1403 2484 
Q 997 2584 770 2862 
Q 544 3141 544 3541 
Q 544 4100 942 4425 
Q 1341 4750 2034 4750 
Q 2731 4750 3128 4425 
Q 3525 4100 3525 3541 
Q 3525 3141 3298 2862 
Q 3072 2584 2669 2484 
Q 3125 2378 3379 2068 
Q 3634 1759 3634 1313 
Q 3634 634 3220 271 
Q 2806 -91 2034 -91 
Q 1263 -91 848 271 
Q 434 634 434 1313 
Q 434 1759 690 2068 
Q 947 2378 1403 2484 
z
M 1172 3481 
Q 1172 3119 1398 2916 
Q 1625 2713 2034 2713 
Q 2441 2713 2670 2916 
Q 2900 3119 2900 3481 
Q 2900 3844 2670 4047 
Q 2441 4250 2034 4250 
Q 1625 4250 1398 4047 
Q 1172 3844 1172 3481 
z
" transform="scale(0.015625)"></path></defs><use xlink:href="#DejaVuSans-73"></use><use xlink:href="#DejaVuSans-4d" x="52.099609"></use><use xlink:href="#DejaVuSans-41" x="138.378906"></use><use xlink:href="#DejaVuSans-50" x="206.787109"></use><use xlink:href="#DejaVuSans-45" x="267.089844"></use><use xlink:href="#DejaVuSans-20" x="330.273438"></use><use xlink:href="#DejaVuSans-45" x="362.060547"></use><use xlink:href="#DejaVuSans-72" x="425.244141"></use><use xlink:href="#DejaVuSans-72" x="464.607422"></use><use xlink:href="#DejaVuSans-6f" x="503.470703"></use><use xlink:href="#DejaVuSans-72" x="564.652344"></use><use xlink:href="#DejaVuSans-3a" x="604.015625"></use><use xlink:href="#DejaVuSans-20" x="637.707031"></use><use xlink:href="#DejaVuSans-33" x="669.494141"></use><use xlink:href="#DejaVuSans-35" x="733.117188"></use><use xlink:href="#DejaVuSans-2e" x="796.740234"></use><use xlink:href="#DejaVuSans-39" x="828.527344"></use><use xlink:href="#DejaVuSans-38" x="892.150391"></use></g></g><g id="legend_1"><g id="patch_6"><path d="M 456.033012 91.01065 
L 538.2002 91.01065 
Q 540.2002 91.01065 540.2002 89.01065 
L 540.2002 60.6544 
Q 540.2002 58.6544 538.2002 58.6544 
L 456.033012 58.6544 
Q 454.033012 58.6544 454.033012 60.6544 
L 454.033012 89.01065 
Q 454.033012 91.01065 456.033012 91.01065 
z
" style="fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter"></path></g><g id="line2d_28"><path d="M 458.033012 66.752837 
L 468.033012 66.752837 
L 478.033012 66.752837 
" style="fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square"></path></g><g id="text_24"><g transform="translate(486.033012 70.252837)scale(0.1 -0.1)"><defs><path id="DejaVuSans-65" d="M 3597 1894 
L 3597 1613 
L 953 1613 
Q 991 1019 1311 708 
Q 1631 397 2203 397 
Q 2534 397 2845 478 
Q 3156 559 3463 722 
L 3463 178 
Q 3153 47 2828 -22 
Q 2503 -91 2169 -91 
Q 1331 -91 842 396 
Q 353 884 353 1716 
Q 353 2575 817 3079 
Q 1281 3584 2069 3584 
Q 2775 3584 3186 3129 
Q 3597 2675 3597 1894 
z
M 3022 2063 
Q 3016 2534 2758 2815 
Q 2500 3097 2075 3097 
Q 1594 3097 1305 2825 
Q 1016 2553 972 2059 
L 3022 2063 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-66" d="M 2375 4863 
L 2375 4384 
L 1825 4384 
Q 1516 4384 1395 4259 
Q 1275 4134 1275 3809 
L 1275 3500 
L 2222 3500 
L 2222 3053 
L 1275 3053 
L 1275 0 
L 697 0 
L 697 3053 
L 147 3053 
L 147 3500 
L 697 3500 
L 697 3744 
Q 697 4328 969 4595 
Q 1241 4863 1831 4863 
L 2375 4863 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-6e" d="M 3513 2113 
L 3513 0 
L 2938 0 
L 2938 2094 
Q 2938 2591 2744 2837 
Q 2550 3084 2163 3084 
Q 1697 3084 1428 2787 
Q 1159 2491 1159 1978 
L 1159 0 
L 581 0 
L 581 3500 
L 1159 3500 
L 1159 2956 
Q 1366 3272 1645 3428 
Q 1925 3584 2291 3584 
Q 2894 3584 3203 3211 
Q 3513 2838 3513 2113 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-63" d="M 3122 3366 
L 3122 2828 
Q 2878 2963 2633 3030 
Q 2388 3097 2138 3097 
Q 1578 3097 1268 2742 
Q 959 2388 959 1747 
Q 959 1106 1268 751 
Q 1578 397 2138 397 
Q 2388 397 2633 464 
Q 2878 531 3122 666 
L 3122 134 
Q 2881 22 2623 -34 
Q 2366 -91 2075 -91 
Q 1284 -91 818 406 
Q 353 903 353 1747 
Q 353 2603 823 3093 
Q 1294 3584 2113 3584 
Q 2378 3584 2631 3529 
Q 2884 3475 3122 3366 
z
" transform="scale(0.015625)"></path></defs><use xlink:href="#DejaVuSans-72"></use><use xlink:href="#DejaVuSans-65" x="38.863281"></use><use xlink:href="#DejaVuSans-66" x="100.386719"></use><use xlink:href="#DejaVuSans-65" x="135.591797"></use><use xlink:href="#DejaVuSans-72" x="197.115234"></use><use xlink:href="#DejaVuSans-65" x="235.978516"></use><use xlink:href="#DejaVuSans-6e" x="297.501953"></use><use xlink:href="#DejaVuSans-63" x="360.880859"></use><use xlink:href="#DejaVuSans-65" x="415.861328"></use></g></g><g id="line2d_29"><path d="M 458.033012 81.430963 
L 468.033012 81.430963 
L 478.033012 81.430963 
" style="fill: none; stroke: #ff7f0e; stroke-opacity: 0.6; stroke-width: 1.5; stroke-linecap: square"></path></g><g id="text_25"><g transform="translate(486.033012 84.930963)scale(0.1 -0.1)"><defs><path id="DejaVuSans-70" d="M 1159 525 
L 1159 -1331 
L 581 -1331 
L 581 3500 
L 1159 3500 
L 1159 2969 
Q 1341 3281 1617 3432 
Q 1894 3584 2278 3584 
Q 2916 3584 3314 3078 
Q 3713 2572 3713 1747 
Q 3713 922 3314 415 
Q 2916 -91 2278 -91 
Q 1894 -91 1617 61 
Q 1341 213 1159 525 
z
M 3116 1747 
Q 3116 2381 2855 2742 
Q 2594 3103 2138 3103 
Q 1681 3103 1420 2742 
Q 1159 2381 1159 1747 
Q 1159 1113 1420 752 
Q 1681 391 2138 391 
Q 2594 391 2855 752 
Q 3116 1113 3116 1747 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-64" d="M 2906 2969 
L 2906 4863 
L 3481 4863 
L 3481 0 
L 2906 0 
L 2906 525 
Q 2725 213 2448 61 
Q 2172 -91 1784 -91 
Q 1150 -91 751 415 
Q 353 922 353 1747 
Q 353 2572 751 3078 
Q 1150 3584 1784 3584 
Q 2172 3584 2448 3432 
Q 2725 3281 2906 2969 
z
M 947 1747 
Q 947 1113 1208 752 
Q 1469 391 1925 391 
Q 2381 391 2643 752 
Q 2906 1113 2906 1747 
Q 2906 2381 2643 2742 
Q 2381 3103 1925 3103 
Q 1469 3103 1208 2742 
Q 947 2381 947 1747 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-69" d="M 603 3500 
L 1178 3500 
L 1178 0 
L 603 0 
L 603 3500 
z
M 603 4863 
L 1178 4863 
L 1178 4134 
L 603 4134 
L 603 4863 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-74" d="M 1172 4494 
L 1172 3500 
L 2356 3500 
L 2356 3053 
L 1172 3053 
L 1172 1153 
Q 1172 725 1289 603 
Q 1406 481 1766 481 
L 2356 481 
L 2356 0 
L 1766 0 
Q 1100 0 847 248 
Q 594 497 594 1153 
L 594 3053 
L 172 3053 
L 172 3500 
L 594 3500 
L 594 4494 
L 1172 4494 
z
" transform="scale(0.015625)"></path></defs><use xlink:href="#DejaVuSans-70"></use><use xlink:href="#DejaVuSans-72" x="63.476562"></use><use xlink:href="#DejaVuSans-65" x="102.339844"></use><use xlink:href="#DejaVuSans-64" x="163.863281"></use><use xlink:href="#DejaVuSans-69" x="227.339844"></use><use xlink:href="#DejaVuSans-63" x="255.123047"></use><use xlink:href="#DejaVuSans-74" x="310.103516"></use><use xlink:href="#DejaVuSans-69" x="349.3125"></use><use xlink:href="#DejaVuSans-6f" x="377.095703"></use><use xlink:href="#DejaVuSans-6e" x="438.277344"></use></g></g></g></g></g><defs><clipPath id="p4bc3fb7813"><rect x="200.9178" y="53.6544" width="344.2824" height="344.2824"></rect></clipPath></defs></svg> <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="323" height="330" viewBox="200 100 376 230" xmlns="http://www.w3.org/2000/svg" version="1.1"><metadata><rdf:RDF xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"><cc:Work><dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"></dc:type><dc:date>2024-02-22T08:05:52.596616</dc:date><dc:format>image/svg+xml</dc:format><dc:creator><cc:Agent><dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title></cc:Agent></dc:creator></cc:Work></rdf:RDF></metadata><defs><style type="text/css">* {
				stroke-linejoin: round;
				stroke-linecap: butt;
			}</style></defs><g id="figure_1"><g id="patch_1"><path d="M 0 426.96 
L 727.92 426.96 
L 727.92 0 
L 0 0 
z
" style="fill: #ffffff"></path></g><g id="patch_2"><path d="M 208.6794 379.9944 
L 537.4386 379.9944 
L 537.4386 51.2352 
L 208.6794 51.2352 
z
" style="fill: #ffffff"></path></g><g id="pane3d_1"><g id="patch_3"><path d="M 233.502987 298.932917 
L 342.070011 207.929884 
L 340.560826 76.687243 
L 226.798309 159.705946 
" style="fill: #f2f2f2; opacity: 0.5; stroke: #f2f2f2; stroke-linejoin: miter"></path></g></g><g id="pane3d_2"><g id="patch_4"><path d="M 342.070011 207.929884 
L 516.281349 258.566242 
L 522.498338 122.803099 
L 340.560826 76.687243 
" style="fill: #e6e6e6; opacity: 0.5; stroke: #e6e6e6; stroke-linejoin: miter"></path></g></g><g id="pane3d_3"><g id="patch_5"><path d="M 233.502987 298.932917 
L 418.175514 359.246964 
L 516.281349 258.566242 
L 342.070011 207.929884 
" style="fill: #ececec; opacity: 0.5; stroke: #ececec; stroke-linejoin: miter"></path></g></g><g id="axis3d_1"><g id="line2d_1"><path d="M 233.502987 298.932917 
L 418.175514 359.246964 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="Line3DCollection_1"><path d="M 249.12005 304.03345 
L 356.862064 212.22935 
L 355.979081 80.595321 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 275.449069 312.632508 
L 381.775148 219.4706 
L 381.959315 87.180553 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 302.185931 321.364766 
L 407.042027 226.814684 
L 408.324517 93.863363 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 329.340184 330.233345 
L 432.67029 234.263809 
L 435.083306 100.645936 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 356.92168 339.241462 
L 458.667748 241.820243 
L 462.244562 107.530523 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 384.940582 348.392435 
L 485.042434 249.486323 
L 489.817434 114.519442 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 413.407378 357.689691 
L 511.802621 257.264453 
L 517.811351 121.615084 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path></g><g id="xtick_1"><g id="line2d_2"><path d="M 250.05836 303.233941 
L 247.239398 305.635903 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_1"><g transform="translate(231.047554 327.356236)scale(0.1 -0.1)"><defs><path id="DejaVuSans-2212" d="M 678 2272 
L 4684 2272 
L 4684 1741 
L 678 1741 
L 678 2272 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-31" d="M 794 531 
L 1825 531 
L 1825 4091 
L 703 3866 
L 703 4441 
L 1819 4666 
L 2450 4666 
L 2450 531 
L 3481 531 
L 3481 0 
L 794 0 
L 794 531 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-30" d="M 2034 4250 
Q 1547 4250 1301 3770 
Q 1056 3291 1056 2328 
Q 1056 1369 1301 889 
Q 1547 409 2034 409 
Q 2525 409 2770 889 
Q 3016 1369 3016 2328 
Q 3016 3291 2770 3770 
Q 2525 4250 2034 4250 
z
M 2034 4750 
Q 2819 4750 3233 4129 
Q 3647 3509 3647 2328 
Q 3647 1150 3233 529 
Q 2819 -91 2034 -91 
Q 1250 -91 836 529 
Q 422 1150 422 2328 
Q 422 3509 836 4129 
Q 1250 4750 2034 4750 
z
" transform="scale(0.015625)"></path></defs><use xlink:href="#DejaVuSans-2212"></use><use xlink:href="#DejaVuSans-31" x="83.789062"></use><use xlink:href="#DejaVuSans-30" x="147.412109"></use></g></g></g><g id="xtick_2"><g id="line2d_3"><path d="M 276.375627 311.820666 
L 273.591942 314.259705 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_2"><g transform="translate(260.579731 336.1026)scale(0.1 -0.1)"><defs><path id="DejaVuSans-35" d="M 691 4666 
L 3169 4666 
L 3169 4134 
L 1269 4134 
L 1269 2991 
Q 1406 3038 1543 3061 
Q 1681 3084 1819 3084 
Q 2600 3084 3056 2656 
Q 3513 2228 3513 1497 
Q 3513 744 3044 326 
Q 2575 -91 1722 -91 
Q 1428 -91 1123 -41 
Q 819 9 494 109 
L 494 744 
Q 775 591 1075 516 
Q 1375 441 1709 441 
Q 2250 441 2565 725 
Q 2881 1009 2881 1497 
Q 2881 1984 2565 2268 
Q 2250 2553 1709 2553 
Q 1456 2553 1204 2497 
Q 953 2441 691 2322 
L 691 4666 
z
" transform="scale(0.015625)"></path></defs><use xlink:href="#DejaVuSans-2212"></use><use xlink:href="#DejaVuSans-35" x="83.789062"></use></g></g></g><g id="xtick_3"><g id="line2d_4"><path d="M 303.100258 320.540306 
L 300.353286 323.017286 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_3"><g transform="translate(291.529931 344.984861)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-30"></use></g></g></g><g id="xtick_4"><g id="line2d_5"><path d="M 330.241785 329.395968 
L 327.533016 331.911782 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_4"><g transform="translate(318.709333 354.006211)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-35"></use></g></g></g><g id="xtick_5"><g id="line2d_6"><path d="M 357.81004 338.390863 
L 355.141022 340.94643 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_5"><g transform="translate(343.136452 363.169943)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-31"></use><use xlink:href="#DejaVuSans-30" x="63.623047"></use></g></g></g><g id="xtick_6"><g id="line2d_7"><path d="M 385.815166 347.528298 
L 383.187506 350.12457 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_6"><g transform="translate(371.184023 372.479454)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-31"></use><use xlink:href="#DejaVuSans-35" x="63.623047"></use></g></g></g><g id="xtick_7"><g id="line2d_8"><path d="M 414.267631 356.81169 
L 411.682999 359.449646 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_7"><g transform="translate(399.681362 381.938252)scale(0.1 -0.1)"><defs><path id="DejaVuSans-32" d="M 1228 531 
L 3431 531 
L 3431 0 
L 469 0 
L 469 531 
Q 828 903 1448 1529 
Q 2069 2156 2228 2338 
Q 2531 2678 2651 2914 
Q 2772 3150 2772 3378 
Q 2772 3750 2511 3984 
Q 2250 4219 1831 4219 
Q 1534 4219 1204 4116 
Q 875 4013 500 3803 
L 500 4441 
Q 881 4594 1212 4672 
Q 1544 4750 1819 4750 
Q 2544 4750 2975 4387 
Q 3406 4025 3406 3419 
Q 3406 3131 3298 2873 
Q 3191 2616 2906 2266 
Q 2828 2175 2409 1742 
Q 1991 1309 1228 531 
z
" transform="scale(0.015625)"></path></defs><use xlink:href="#DejaVuSans-32"></use><use xlink:href="#DejaVuSans-30" x="63.623047"></use></g></g></g></g><g id="axis3d_2"><g id="line2d_9"><path d="M 516.281349 258.566242 
L 418.175514 359.246964 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="Line3DCollection_2"><path d="M 240.436097 149.75371 
L 246.474509 288.05993 
L 429.942784 347.17085 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 254.464746 139.516241 
L 259.830107 276.865003 
L 442.045487 334.750499 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 268.198738 129.493799 
L 272.917294 265.895063 
L 453.892199 322.592858 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 281.64726 119.67968 
L 285.744083 255.143395 
L 465.490957 310.689679 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 294.819121 110.067455 
L 298.318168 244.603547 
L 476.849465 299.033056 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 307.722772 100.650959 
L 310.646944 234.269323 
L 487.975111 287.615407 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 320.366322 91.424272 
L 322.73752 224.134762 
L 498.874983 276.429456 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 332.757557 82.381713 
L 334.596734 214.194134 
L 509.555884 265.468224 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path></g><g id="xtick_8"><g id="line2d_10"><path d="M 428.397034 346.672831 
L 433.038264 348.16817 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_8"><g transform="translate(432.215593 368.129792)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-2212"></use><use xlink:href="#DejaVuSans-31" x="83.789062"></use><use xlink:href="#DejaVuSans-30" x="147.412109"></use></g></g></g><g id="xtick_9"><g id="line2d_11"><path d="M 440.511121 334.263068 
L 445.118128 335.726604 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_9"><g transform="translate(447.368172 355.560636)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-2212"></use><use xlink:href="#DejaVuSans-35" x="83.789062"></use></g></g></g><g id="xtick_10"><g id="line2d_12"><path d="M 452.369083 322.11568 
L 456.94227 323.548418 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_10"><g transform="translate(463.276012 343.257464)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-30"></use></g></g></g><g id="xtick_11"><g id="line2d_13"><path d="M 463.978959 310.222434 
L 468.518724 311.625335 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_11"><g transform="translate(474.748635 331.211919)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-35"></use></g></g></g><g id="xtick_12"><g id="line2d_14"><path d="M 475.348453 298.575437 
L 479.855193 299.949424 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_12"><g transform="translate(482.80226 319.415995)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-31"></use><use xlink:href="#DejaVuSans-30" x="63.623047"></use></g></g></g><g id="xtick_13"><g id="line2d_15"><path d="M 486.484955 287.167119 
L 490.959062 288.513076 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_13"><g transform="translate(493.806702 307.86201)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-31"></use><use xlink:href="#DejaVuSans-35" x="63.623047"></use></g></g></g><g id="xtick_14"><g id="line2d_16"><path d="M 497.395553 275.990218 
L 501.837418 277.308995 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_14"><g transform="translate(504.587729 296.542598)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-32"></use><use xlink:href="#DejaVuSans-30" x="63.623047"></use></g></g></g><g id="xtick_15"><g id="line2d_17"><path d="M 508.087053 265.037763 
L 512.497062 266.330175 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_15"><g transform="translate(515.152076 285.450687)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-32"></use><use xlink:href="#DejaVuSans-35" x="63.623047"></use></g></g></g></g><g id="axis3d_3"><g id="line2d_18"><path d="M 516.281349 258.566242 
L 522.498338 122.803099 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="Line3DCollection_3"><path d="M 517.183355 238.868743 
L 341.850652 188.853861 
L 232.531625 278.761961 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 518.455062 211.097897 
L 341.541614 161.97907 
L 231.161327 250.306844 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 519.750139 182.816736 
L 341.227171 134.634281 
L 229.764878 221.308662 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path><path d="M 521.069234 154.011062 
L 340.90718 106.807055 
L 228.34152 191.751719 
" style="fill: none; stroke: #b0b0b0; stroke-width: 0.8"></path></g><g id="xtick_16"><g id="line2d_19"><path d="M 515.711383 238.448853 
L 520.130822 239.709529 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_16"><g transform="translate(529.196107 243.891935)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-31"></use><use xlink:href="#DejaVuSans-30" x="63.623047"></use></g></g></g><g id="xtick_17"><g id="line2d_20"><path d="M 516.969183 210.685353 
L 521.43041 211.923983 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_17"><g transform="translate(530.63156 216.166191)scale(0.1 -0.1)"><use xlink:href="#DejaVuSans-32"></use><use xlink:href="#DejaVuSans-30" x="63.623047"></use></g></g></g><g id="xtick_18"><g id="line2d_21"><path d="M 518.250088 182.41188 
L 522.753898 183.627436 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_18"><g transform="translate(532.093326 187.932227)scale(0.1 -0.1)"><defs><path id="DejaVuSans-33" d="M 2597 2516 
Q 3050 2419 3304 2112 
Q 3559 1806 3559 1356 
Q 3559 666 3084 287 
Q 2609 -91 1734 -91 
Q 1441 -91 1130 -33 
Q 819 25 488 141 
L 488 750 
Q 750 597 1062 519 
Q 1375 441 1716 441 
Q 2309 441 2620 675 
Q 2931 909 2931 1356 
Q 2931 1769 2642 2001 
Q 2353 2234 1838 2234 
L 1294 2234 
L 1294 2753 
L 1863 2753 
Q 2328 2753 2575 2939 
Q 2822 3125 2822 3475 
Q 2822 3834 2567 4026 
Q 2313 4219 1838 4219 
Q 1578 4219 1281 4162 
Q 984 4106 628 3988 
L 628 4550 
Q 988 4650 1302 4700 
Q 1616 4750 1894 4750 
Q 2613 4750 3031 4423 
Q 3450 4097 3450 3541 
Q 3450 3153 3228 2886 
Q 3006 2619 2597 2516 
z
" transform="scale(0.015625)"></path></defs><use xlink:href="#DejaVuSans-33"></use><use xlink:href="#DejaVuSans-30" x="63.623047"></use></g></g></g><g id="xtick_19"><g id="line2d_22"><path d="M 519.554738 153.614251 
L 524.101953 154.80566 
" style="fill: none; stroke: #000000; stroke-width: 0.8; stroke-linecap: square"></path></g><g id="text_19"><g transform="translate(533.582133 159.175941)scale(0.1 -0.1)"><defs><path id="DejaVuSans-34" d="M 2419 4116 
L 825 1625 
L 2419 1625 
L 2419 4116 
z
M 2253 4666 
L 3047 4666 
L 3047 1625 
L 3713 1625 
L 3713 1100 
L 3047 1100 
L 3047 0 
L 2419 0 
L 2419 1100 
L 313 1100 
L 313 1709 
L 2253 4666 
z
" transform="scale(0.015625)"></path></defs><use xlink:href="#DejaVuSans-34"></use><use xlink:href="#DejaVuSans-30" x="63.623047"></use></g></g></g></g><g id="axes_1"><g id="line2d_23"><path d="M 340.371773 265.949485 
L 340.438149 267.076391 
L 340.510442 268.154448 
L 340.590015 269.185633 
L 340.678672 270.17142 
L 340.778436 271.113098 
L 340.891525 272.011853 
L 341.019969 272.868832 
L 341.166874 273.684636 
L 341.335855 274.459637 
L 341.530907 275.194047 
L 341.75574 275.888129 
L 342.016177 276.541289 
L 342.319101 277.152518 
L 342.672124 277.720512 
L 343.082343 278.244153 
L 343.560887 278.720683 
L 344.121064 279.146464 
L 344.77754 279.517218 
L 345.544067 279.829187 
L 346.441989 280.075048 
L 347.497042 280.245394 
L 348.73737 280.32932 
L 350.189735 280.317306 
L 351.894631 280.191361 
L 353.900947 279.928146 
L 356.260928 279.500755 
L 359.026609 278.885549 
L 362.271155 278.038036 
L 366.080463 276.899775 
L 370.540314 275.410857 
L 375.747788 273.496104 
L 381.81087 271.050325 
L 388.836545 267.955504 
L 396.928041 264.067675 
L 406.153044 259.221171 
L 416.567785 253.231626 
L 428.08875 245.932345 
L 440.542642 237.185768 
L 453.562271 226.942407 
L 466.458867 215.39211 
L 478.318695 202.925399 
L 487.868415 190.405516 
L 493.659705 179.028622 
L 494.400333 170.236612 
L 489.164994 165.409197 
L 478.020499 165.21511 
L 461.911642 169.49347 
L 442.618894 177.045805 
L 422.14557 186.234301 
L 402.231517 195.484181 
L 384.040422 203.717992 
L 368.146546 210.438698 
L 354.660653 215.619288 
L 343.440214 219.472158 
L 334.202528 222.308526 
L 326.63621 224.434961 
L 320.437932 226.095191 
L 315.329034 227.482946 
L 311.073687 228.720766 
L 307.473415 229.887167 
L 304.347343 231.03562 
L 301.565684 232.176447 
L 299.013616 233.312567 
L 296.584657 234.439537 
L 294.209879 235.53618 
L 291.833427 236.578854 
L 289.406924 237.543128 
L 286.884187 238.401693 
L 284.251928 239.123794 
L 281.503428 239.678122 
L 278.636884 240.034374 
L 275.652575 240.157726 
L 272.577427 240.015225 
L 269.458224 239.578983 
L 266.342248 238.821512 
L 263.287167 237.723343 
L 260.369742 236.255411 
L 257.681865 234.434676 
L 255.315952 232.278454 
L 253.362518 229.81266 
L 251.923123 227.089239 
L 251.064108 224.195688 
L 250.840425 221.22367 
L 251.296729 218.284702 
L 252.416158 215.494798 
L 254.157997 212.963343 
L 256.462976 210.795554 
L 259.232631 209.072755 
L 262.351405 207.836412 
L 265.712813 207.11235 
L 269.166872 206.916326 
L 272.617664 207.203307 
L 275.976935 207.922599 
L 279.157361 209.024097 
L 282.091544 210.451441 
L 284.717466 212.127825 
L 287.018892 213.999281 
L 288.979359 216.011962 
L 290.582326 218.11446 
" clip-path="url(#paf9e3e687e)" style="fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square"></path></g><g id="line2d_24"><path d="M 343.067484 268.711158 
L 342.849415 269.189891 
L 342.035681 270.156905 
L 342.516772 270.223096 
L 341.884714 270.340213 
L 341.696497 270.490844 
L 340.860047 271.153906 
L 342.765989 272.422693 
L 342.052458 273.24953 
L 341.674948 274.294007 
L 341.250043 276.176682 
L 340.200799 277.32661 
L 337.38616 278.500854 
L 339.040109 279.081763 
L 336.432673 279.121782 
L 334.928389 279.229111 
L 334.236122 280.216506 
L 333.391269 279.017012 
L 333.210187 278.35014 
L 332.850663 276.574846 
L 334.001245 274.709893 
L 335.603112 272.87056 
L 338.196438 272.005818 
L 338.462207 271.587903 
L 340.844573 271.268801 
L 339.334499 272.223936 
L 337.024818 272.824246 
L 336.457011 270.113334 
L 332.798522 265.772247 
L 331.465594 259.674352 
L 331.118258 252.114442 
L 326.797978 242.055823 
L 324.938926 227.931843 
L 324.524881 215.976824 
L 321.062933 204.324862 
L 319.691456 193.604708 
L 320.03164 183.356635 
L 318.212584 177.37168 
L 319.11747 172.32436 
L 319.501743 169.903976 
L 320.927053 170.475813 
L 320.236213 173.897419 
L 321.47299 177.892791 
L 325.888904 183.290077 
L 326.947474 188.529733 
L 328.689592 193.955711 
L 331.232325 199.137048 
L 332.529993 204.490832 
L 333.80486 210.451971 
L 335.574475 213.942966 
L 335.183073 218.421077 
L 336.389503 220.746495 
L 336.425454 222.394329 
L 336.683235 224.673374 
L 338.927599 225.795944 
L 335.48215 227.91316 
L 338.364649 229.107394 
L 335.954748 232.300827 
L 336.73347 232.914346 
L 335.974287 232.063888 
L 338.767371 233.234449 
L 338.648115 234.126266 
L 338.510999 234.543538 
L 337.113248 233.448848 
L 339.893577 232.529868 
L 340.406392 230.72561 
L 340.87618 230.465076 
L 339.718629 230.18814 
L 341.425329 228.71954 
L 341.601204 226.86489 
L 344.420188 226.090457 
L 341.860125 222.04438 
L 343.297678 220.364622 
L 341.465943 216.913871 
L 341.572628 213.904938 
L 340.912721 211.410274 
L 340.216287 208.956909 
L 339.498606 207.15358 
L 339.722549 205.96997 
L 338.967128 205.201759 
L 337.68664 205.033368 
L 336.906737 204.409385 
L 338.13571 203.953481 
L 336.670969 205.030466 
L 340.223231 205.057573 
L 339.245978 206.871992 
L 341.162334 208.07489 
L 340.208941 209.109309 
L 342.404249 211.736929 
L 343.262136 213.850729 
L 342.307846 216.857526 
L 342.697284 218.709594 
L 345.492611 220.243499 
L 344.780236 221.453629 
L 345.805869 224.164857 
L 344.931078 225.368622 
L 342.721365 226.834047 
L 342.715889 229.016518 
L 340.955678 227.984725 
L 341.549341 228.980199 
" clip-path="url(#paf9e3e687e)" style="fill: none; stroke: #ff7f0e; stroke-opacity: 0.6; stroke-width: 1.5; stroke-linecap: square"></path></g><g id="text_20"><g transform="translate(311.8965 45.2352)scale(0.12 -0.12)"><defs><path id="DejaVuSans-73" d="M 2834 3397 
L 2834 2853 
Q 2591 2978 2328 3040 
Q 2066 3103 1784 3103 
Q 1356 3103 1142 2972 
Q 928 2841 928 2578 
Q 928 2378 1081 2264 
Q 1234 2150 1697 2047 
L 1894 2003 
Q 2506 1872 2764 1633 
Q 3022 1394 3022 966 
Q 3022 478 2636 193 
Q 2250 -91 1575 -91 
Q 1294 -91 989 -36 
Q 684 19 347 128 
L 347 722 
Q 666 556 975 473 
Q 1284 391 1588 391 
Q 1994 391 2212 530 
Q 2431 669 2431 922 
Q 2431 1156 2273 1281 
Q 2116 1406 1581 1522 
L 1381 1569 
Q 847 1681 609 1914 
Q 372 2147 372 2553 
Q 372 3047 722 3315 
Q 1072 3584 1716 3584 
Q 2034 3584 2315 3537 
Q 2597 3491 2834 3397 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-4d" d="M 628 4666 
L 1569 4666 
L 2759 1491 
L 3956 4666 
L 4897 4666 
L 4897 0 
L 4281 0 
L 4281 4097 
L 3078 897 
L 2444 897 
L 1241 4097 
L 1241 0 
L 628 0 
L 628 4666 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-41" d="M 2188 4044 
L 1331 1722 
L 3047 1722 
L 2188 4044 
z
M 1831 4666 
L 2547 4666 
L 4325 0 
L 3669 0 
L 3244 1197 
L 1141 1197 
L 716 0 
L 50 0 
L 1831 4666 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-50" d="M 1259 4147 
L 1259 2394 
L 2053 2394 
Q 2494 2394 2734 2622 
Q 2975 2850 2975 3272 
Q 2975 3691 2734 3919 
Q 2494 4147 2053 4147 
L 1259 4147 
z
M 628 4666 
L 2053 4666 
Q 2838 4666 3239 4311 
Q 3641 3956 3641 3272 
Q 3641 2581 3239 2228 
Q 2838 1875 2053 1875 
L 1259 1875 
L 1259 0 
L 628 0 
L 628 4666 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-45" d="M 628 4666 
L 3578 4666 
L 3578 4134 
L 1259 4134 
L 1259 2753 
L 3481 2753 
L 3481 2222 
L 1259 2222 
L 1259 531 
L 3634 531 
L 3634 0 
L 628 0 
L 628 4666 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-20" transform="scale(0.015625)"></path><path id="DejaVuSans-72" d="M 2631 2963 
Q 2534 3019 2420 3045 
Q 2306 3072 2169 3072 
Q 1681 3072 1420 2755 
Q 1159 2438 1159 1844 
L 1159 0 
L 581 0 
L 581 3500 
L 1159 3500 
L 1159 2956 
Q 1341 3275 1631 3429 
Q 1922 3584 2338 3584 
Q 2397 3584 2469 3576 
Q 2541 3569 2628 3553 
L 2631 2963 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-6f" d="M 1959 3097 
Q 1497 3097 1228 2736 
Q 959 2375 959 1747 
Q 959 1119 1226 758 
Q 1494 397 1959 397 
Q 2419 397 2687 759 
Q 2956 1122 2956 1747 
Q 2956 2369 2687 2733 
Q 2419 3097 1959 3097 
z
M 1959 3584 
Q 2709 3584 3137 3096 
Q 3566 2609 3566 1747 
Q 3566 888 3137 398 
Q 2709 -91 1959 -91 
Q 1206 -91 779 398 
Q 353 888 353 1747 
Q 353 2609 779 3096 
Q 1206 3584 1959 3584 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-3a" d="M 750 794 
L 1409 794 
L 1409 0 
L 750 0 
L 750 794 
z
M 750 3309 
L 1409 3309 
L 1409 2516 
L 750 2516 
L 750 3309 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-2e" d="M 684 794 
L 1344 794 
L 1344 0 
L 684 0 
L 684 794 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-36" d="M 2113 2584 
Q 1688 2584 1439 2293 
Q 1191 2003 1191 1497 
Q 1191 994 1439 701 
Q 1688 409 2113 409 
Q 2538 409 2786 701 
Q 3034 994 3034 1497 
Q 3034 2003 2786 2293 
Q 2538 2584 2113 2584 
z
M 3366 4563 
L 3366 3988 
Q 3128 4100 2886 4159 
Q 2644 4219 2406 4219 
Q 1781 4219 1451 3797 
Q 1122 3375 1075 2522 
Q 1259 2794 1537 2939 
Q 1816 3084 2150 3084 
Q 2853 3084 3261 2657 
Q 3669 2231 3669 1497 
Q 3669 778 3244 343 
Q 2819 -91 2113 -91 
Q 1303 -91 875 529 
Q 447 1150 447 2328 
Q 447 3434 972 4092 
Q 1497 4750 2381 4750 
Q 2619 4750 2861 4703 
Q 3103 4656 3366 4563 
z
" transform="scale(0.015625)"></path></defs><use xlink:href="#DejaVuSans-73"></use><use xlink:href="#DejaVuSans-4d" x="52.099609"></use><use xlink:href="#DejaVuSans-41" x="138.378906"></use><use xlink:href="#DejaVuSans-50" x="206.787109"></use><use xlink:href="#DejaVuSans-45" x="267.089844"></use><use xlink:href="#DejaVuSans-20" x="330.273438"></use><use xlink:href="#DejaVuSans-45" x="362.060547"></use><use xlink:href="#DejaVuSans-72" x="425.244141"></use><use xlink:href="#DejaVuSans-72" x="464.607422"></use><use xlink:href="#DejaVuSans-6f" x="503.470703"></use><use xlink:href="#DejaVuSans-72" x="564.652344"></use><use xlink:href="#DejaVuSans-3a" x="604.015625"></use><use xlink:href="#DejaVuSans-20" x="637.707031"></use><use xlink:href="#DejaVuSans-31" x="669.494141"></use><use xlink:href="#DejaVuSans-33" x="733.117188"></use><use xlink:href="#DejaVuSans-34" x="796.740234"></use><use xlink:href="#DejaVuSans-2e" x="860.363281"></use><use xlink:href="#DejaVuSans-36" x="892.150391"></use><use xlink:href="#DejaVuSans-36" x="955.773438"></use></g></g><g id="legend_1"><g id="patch_6"><path d="M 448.271412 88.59145 
L 530.4386 88.59145 
Q 532.4386 88.59145 532.4386 86.59145 
L 532.4386 58.2352 
Q 532.4386 56.2352 530.4386 56.2352 
L 448.271412 56.2352 
Q 446.271412 56.2352 446.271412 58.2352 
L 446.271412 86.59145 
Q 446.271412 88.59145 448.271412 88.59145 
z
" style="fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter"></path></g><g id="line2d_25"><path d="M 450.271412 64.333638 
L 460.271412 64.333638 
L 470.271412 64.333638 
" style="fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square"></path></g><g id="text_21"><g transform="translate(478.271412 67.833638)scale(0.1 -0.1)"><defs><path id="DejaVuSans-65" d="M 3597 1894 
L 3597 1613 
L 953 1613 
Q 991 1019 1311 708 
Q 1631 397 2203 397 
Q 2534 397 2845 478 
Q 3156 559 3463 722 
L 3463 178 
Q 3153 47 2828 -22 
Q 2503 -91 2169 -91 
Q 1331 -91 842 396 
Q 353 884 353 1716 
Q 353 2575 817 3079 
Q 1281 3584 2069 3584 
Q 2775 3584 3186 3129 
Q 3597 2675 3597 1894 
z
M 3022 2063 
Q 3016 2534 2758 2815 
Q 2500 3097 2075 3097 
Q 1594 3097 1305 2825 
Q 1016 2553 972 2059 
L 3022 2063 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-66" d="M 2375 4863 
L 2375 4384 
L 1825 4384 
Q 1516 4384 1395 4259 
Q 1275 4134 1275 3809 
L 1275 3500 
L 2222 3500 
L 2222 3053 
L 1275 3053 
L 1275 0 
L 697 0 
L 697 3053 
L 147 3053 
L 147 3500 
L 697 3500 
L 697 3744 
Q 697 4328 969 4595 
Q 1241 4863 1831 4863 
L 2375 4863 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-6e" d="M 3513 2113 
L 3513 0 
L 2938 0 
L 2938 2094 
Q 2938 2591 2744 2837 
Q 2550 3084 2163 3084 
Q 1697 3084 1428 2787 
Q 1159 2491 1159 1978 
L 1159 0 
L 581 0 
L 581 3500 
L 1159 3500 
L 1159 2956 
Q 1366 3272 1645 3428 
Q 1925 3584 2291 3584 
Q 2894 3584 3203 3211 
Q 3513 2838 3513 2113 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-63" d="M 3122 3366 
L 3122 2828 
Q 2878 2963 2633 3030 
Q 2388 3097 2138 3097 
Q 1578 3097 1268 2742 
Q 959 2388 959 1747 
Q 959 1106 1268 751 
Q 1578 397 2138 397 
Q 2388 397 2633 464 
Q 2878 531 3122 666 
L 3122 134 
Q 2881 22 2623 -34 
Q 2366 -91 2075 -91 
Q 1284 -91 818 406 
Q 353 903 353 1747 
Q 353 2603 823 3093 
Q 1294 3584 2113 3584 
Q 2378 3584 2631 3529 
Q 2884 3475 3122 3366 
z
" transform="scale(0.015625)"></path></defs><use xlink:href="#DejaVuSans-72"></use><use xlink:href="#DejaVuSans-65" x="38.863281"></use><use xlink:href="#DejaVuSans-66" x="100.386719"></use><use xlink:href="#DejaVuSans-65" x="135.591797"></use><use xlink:href="#DejaVuSans-72" x="197.115234"></use><use xlink:href="#DejaVuSans-65" x="235.978516"></use><use xlink:href="#DejaVuSans-6e" x="297.501953"></use><use xlink:href="#DejaVuSans-63" x="360.880859"></use><use xlink:href="#DejaVuSans-65" x="415.861328"></use></g></g><g id="line2d_26"><path d="M 450.271412 79.011763 
L 460.271412 79.011763 
L 470.271412 79.011763 
" style="fill: none; stroke: #ff7f0e; stroke-opacity: 0.6; stroke-width: 1.5; stroke-linecap: square"></path></g><g id="text_22"><g transform="translate(478.271412 82.511763)scale(0.1 -0.1)"><defs><path id="DejaVuSans-70" d="M 1159 525 
L 1159 -1331 
L 581 -1331 
L 581 3500 
L 1159 3500 
L 1159 2969 
Q 1341 3281 1617 3432 
Q 1894 3584 2278 3584 
Q 2916 3584 3314 3078 
Q 3713 2572 3713 1747 
Q 3713 922 3314 415 
Q 2916 -91 2278 -91 
Q 1894 -91 1617 61 
Q 1341 213 1159 525 
z
M 3116 1747 
Q 3116 2381 2855 2742 
Q 2594 3103 2138 3103 
Q 1681 3103 1420 2742 
Q 1159 2381 1159 1747 
Q 1159 1113 1420 752 
Q 1681 391 2138 391 
Q 2594 391 2855 752 
Q 3116 1113 3116 1747 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-64" d="M 2906 2969 
L 2906 4863 
L 3481 4863 
L 3481 0 
L 2906 0 
L 2906 525 
Q 2725 213 2448 61 
Q 2172 -91 1784 -91 
Q 1150 -91 751 415 
Q 353 922 353 1747 
Q 353 2572 751 3078 
Q 1150 3584 1784 3584 
Q 2172 3584 2448 3432 
Q 2725 3281 2906 2969 
z
M 947 1747 
Q 947 1113 1208 752 
Q 1469 391 1925 391 
Q 2381 391 2643 752 
Q 2906 1113 2906 1747 
Q 2906 2381 2643 2742 
Q 2381 3103 1925 3103 
Q 1469 3103 1208 2742 
Q 947 2381 947 1747 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-69" d="M 603 3500 
L 1178 3500 
L 1178 0 
L 603 0 
L 603 3500 
z
M 603 4863 
L 1178 4863 
L 1178 4134 
L 603 4134 
L 603 4863 
z
" transform="scale(0.015625)"></path><path id="DejaVuSans-74" d="M 1172 4494 
L 1172 3500 
L 2356 3500 
L 2356 3053 
L 1172 3053 
L 1172 1153 
Q 1172 725 1289 603 
Q 1406 481 1766 481 
L 2356 481 
L 2356 0 
L 1766 0 
Q 1100 0 847 248 
Q 594 497 594 1153 
L 594 3053 
L 172 3053 
L 172 3500 
L 594 3500 
L 594 4494 
L 1172 4494 
z
" transform="scale(0.015625)"></path></defs><use xlink:href="#DejaVuSans-70"></use><use xlink:href="#DejaVuSans-72" x="63.476562"></use><use xlink:href="#DejaVuSans-65" x="102.339844"></use><use xlink:href="#DejaVuSans-64" x="163.863281"></use><use xlink:href="#DejaVuSans-69" x="227.339844"></use><use xlink:href="#DejaVuSans-63" x="255.123047"></use><use xlink:href="#DejaVuSans-74" x="310.103516"></use><use xlink:href="#DejaVuSans-69" x="349.3125"></use><use xlink:href="#DejaVuSans-6f" x="377.095703"></use><use xlink:href="#DejaVuSans-6e" x="438.277344"></use></g></g></g></g></g><defs><clipPath id="paf9e3e687e"><rect x="208.6794" y="51.2352" width="328.7592" height="328.7592"></rect></clipPath></defs></svg></div> <figcaption class="text-center text-xs mt-2 mx-36">Samples of three different 100-point predictions from Model 1 with small, medium, and
			large sMAPE errors</figcaption></figure> <p class="my-2 indent-8 ">One interesting observation in all three graphs is that there appears to be a kind of
		&quot;point of divergence&quot; on the prediction before which the average error is very low and after
		which the error grows quickly. In the first graph, this point is about in the middle of the
		prediction, in the second it is maybe one third of the way into the prediction, and in the
		third it is near the beginning. If we look at the predictions of adjacent windows, we see
		that the behavior at this point is consisent across the windows, indicating that there is
		something about the system&#39;s behavior in this region that is very difficult for this model
		to fit, regardless of its alignment within the prediction window.</p> <figure class="mt-6 mb-6 self-center"><img class="m-auto" src="../model-1-pod.gif" alt="prediction point of divergence" width="450" height="350"> <figcaption class="text-center text-xs mt-2 mx-36">The behavior of the model near the origin, which is a critical point of the system, for
			an especially challenging case. In contrast to all other regions of this trajectory, the
			model seems highly uncertain of how the trajectory will evolve shortly after passing
			near the origin.</figcaption></figure> <p class="my-2 indent-8 ">For anyone familiar with dynamical systems theory, it won&#39;t be a surprise that this point
		coincides with one of the three <a href="https://en.wikipedia.org/wiki/Critical_point_(mathematics)" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">critical points</a> of the Lorenz system--in this case, the origin. And in this parameterization, the origin is
		known to be a saddle point comprised of the intersection of a stable 2D manifold and an unstable
		1D manifold. &quot;Stable&quot; means that trajectories near the manifold tend to move towards it even
		when they are perturbed slightly away from it by other forces, while &quot;unstable&quot; implies the opposite.
		(See [<a href="https://doi.org/10.1080/03036758.2018.1434802" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">6</a>] for some excellent visualizations of these manifolds.) Near the origin,
		the unstable manifold is a line that is approximately perpendicular to the Z axis and parallel
		to the lengthwise orientation of the Attractor, which is why the trajectories always diverge
		at the near 90-degree angles that we see in the animations as they approach the origin. And the
		(incredibly complex) topography of the stable 2D manifold determines towards which of the other
		two critical points a trajectory will be deflected [<a href="https://doi.org/10.1080/03036758.2018.1434802" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">6</a>]. From this I conclude
		that, technically, we can say that the primary goal of our neural network is to learn the
		topography of the origin&#39;s stable 2D manifold. As the manifold defines a boundary across
		which trajectories can never pass, we can confine the past and future trajectory of any
		point to be within the boundary.</p><p class="my-2 indent-8 ">We can estimate how unstable the 1D manifold is by calculating the eigenvalues of the
		Jacobian matrix of the system at the origin and assuming the dynamics are approximately
		linear in this region. The eigenvalue with the largest real component dominates the
		dynamics, and by definition, the real part of this eigenvalue for an unstable mainfold will
		be positive, with the dynamics along the manifold being approximated by the expression $f(t) = \exp(\lambda t)$,
		where $\lambda$ equals the real part of the largest eigenvalue. For the Lorenz Attractor,
		this value is $11.8$, so trajectories will be rapidly deflected away from the origin, as
		we see in the below animation:</p>  <figure class="mt-6 mb-6 self-center"><img class="m-auto" src="../trajectories.gif" alt="trajectories approaching origin" width="350" height="300"> <figcaption class="text-center text-xs mt-2 mx-36">The trajectories from the training set all begin at nearly the same point but quickly
			diverge as they approach the critical point at the origin.</figcaption></figure> <p class="my-2 indent-8 ">Given all of this background, it is now unsurprising that the model is struggling to
		predict the behavior of the system near the origin. But we should also note that the model
		does quite well at predicting basically every other region of the system. We just have to
		figure out a way to improve the predictions near the origin, and then we should have a model
		with an overall very robust representation of the Lorenz Attractor. As this model and its
		training set are relatively modest in size, the next most obvious step to try is to
		signifcantly increase both the amount of training data and the model&#39;s capacity, and see if
		those changes alone are enough to resolve the weaknesses of Model 1.</p> <div class="text-xl text-center mt-4 mb-2">Model 2</div> <p class="my-2 indent-8 ">For the next model, I increased the number of unique initial conditions from 25 to 10000,
		and held out 100 for validation and 200 for testing, leaving 9700 unique initial conditions,
		each of length 10,000 points, or about 150 seconds, in the training set. I also expanded the
		range of hyperparameters for tuning to include significantly larger models, both in depth
		and width. After tuning, I arrived at the following settings:</p> <section class="relative block my-4"><ul class="flex flex-col ms-16 ps-2 rounded gap-0.5 bg-gray-100 divide-y divide-gray-200"><li class="flex items-center justify-left"><div class="flex-none w-64 min-w-64">number of stacks</div> <div class="flex-none w-auto relative"><span class="rounded-0.5 p-1 font-mono">4</span></div> </li><li class="flex items-center justify-left"><div class="flex-none w-64 min-w-64">blocks per stack</div> <div class="flex-none w-auto relative"><span class="rounded-0.5 p-1 font-mono">8</span></div> </li><li class="flex items-center justify-left"><div class="flex-none w-64 min-w-64">mlp layer size</div> <div class="flex-none w-auto relative"><span class="rounded-0.5 p-1 font-mono">2048</span></div> </li><li class="flex items-center justify-left"><div class="flex-none w-64 min-w-64">max pooling factors</div> <div class="flex-none w-auto relative"><span class="rounded-0.5 p-1 font-mono">10, 4, 2, 1</span></div> </li><li class="flex items-center justify-left"><div class="flex-none w-64 min-w-64">frequency downsampling factors</div> <div class="flex-none w-auto relative"><span class="rounded-0.5 p-1 font-mono">25, 12, 6, 1</span></div> </li><li class="flex items-center justify-left"><div class="flex-none w-64 min-w-64">batch size</div> <div class="flex-none w-auto relative"><span class="rounded-0.5 p-1 font-mono">512</span></div> </li><li class="flex items-center justify-left"><div class="flex-none w-64 min-w-64"># training steps</div> <div class="flex-none w-auto relative"><span class="rounded-0.5 p-1 font-mono">150000</span></div> </li><li class="flex items-center justify-left"><div class="flex-none w-64 min-w-64">run validation every</div> <div class="flex-none w-auto relative"><span class="rounded-0.5 p-1 font-mono">5000 steps</span></div> </li><li class="flex items-center justify-left"><div class="flex-none w-64 min-w-64">learning rate</div> <div class="flex-none w-auto relative"><span class="rounded-0.5 p-1 font-mono">1e-4</span></div> </li><li class="flex items-center justify-left"><div class="flex-none w-64 min-w-64">learning rate schedule</div> <div class="flex-none w-auto relative"><span class="rounded-0.5 p-1 font-mono">halve whenever validation loss does not decrease</span></div> </li><li class="flex items-center justify-left"><div class="flex-none w-64 min-w-64">all other hyperparameters</div> <div class="flex-none w-auto relative"><span class="rounded-0.5 p-1 font-mono">same as Model 1</span></div> </li><li class="flex items-center justify-left"><div class="flex-none w-64 min-w-64">total trainable parameters</div> <div class="flex-none w-auto relative"><span class="rounded-0.5 p-1 font-mono">~645 million</span></div> </li></ul></section> <p class="mt-2" data-svelte-h="svelte-1dsw2lx">Note that Model 2 has roughly 32x the number of trainable parameters as Model 1. I&#39;ve
		increased the depth (number of stacks, blocks per stack) and width (mlp layer size) of the
		network, and I&#39;ve also significantly increased the amount of compression in the initial
		stacks. Because the network is much deeper, I also added layer normalization after each
		block to try to help reduce convergence time. Lastly, I increased the number of training
		steps and reduced the initial learning rate by an order of magnitude, and I modified the
		learning rate schedule to reduce by half whenever the validation loss does not decrease from
		the previous validation step.</p> <figure class="mb-2 self-center"><img class="m-auto" src="../Model2ErrDist.png" alt="" width="600" height="600"><figcaption class="text-center text-xs mt-2 mx-36">Model 2 vs Model 1 - sMAPE error distribution.</figcaption></figure> <p class="my-2 indent-8 ">From the plot, we see a significant increase in the first bin and a reduction in every
		subsequent bin of the per-window error histogram relative to Model 1, so the larger dataset
		and new hyperparameter tunings have a definite and significant positive impact. 99% of
		windows from Model 2 have a sMAPE less than 6, compared to only 74% for Model 1, and 99.9%
		have a sMAPE less than 40, compared to 98% for Model 1.</p><p class="my-2 indent-8 ">There are, however, still a handful of windows with very large sMAPE errors. We can
		visualize these errors slightly differently to get a better sense of how they are
		distributed within and across the test series:</p> <figure class="-mt-2 mb-2 self-center"><img class="m-auto" src="../Model2Err3d.png" alt="" width="600" height="600"><figcaption class="text-center text-xs mt-2 mx-36">Model 2 - sMAPE errors per series per window in the test set.</figcaption></figure> <p class="my-2 indent-8 ">We see that very large errors occur quite rarely and briefly, with the predictions spending
		most of the time near the ground truth. Let&#39;s check the animation for one of the large
		spikes with a sMAPE greater than 100:</p> <figure><img class="m-auto" src="../model-2-pod.gif" alt="model 2 point of divergence" width="400" height="340"> <figcaption class="text-center text-xs mt-2 mx-36">Model 2 - a trajectory with one of the largest sMAPE errors from the test set. DFO =
			&#39;distance from origin&#39;</figcaption></figure> <p class="my-2 indent-8 ">Not surprisingly, this trajectory passes very close to the origin, and we immediately see
		how similar this failure case is to the one from Model 1. Despite the average improvement
		across all error magnitudes, has the model&#39;s ability to predict the behavior near the
		unstable origin actually improved significantly relative to Model 1? Let&#39;s check:</p> <figure class="-mt-2 mb-2 self-center"><img class="m-auto" src="../Model2DFO.png" alt="distance from origin vs. sMAPE" width="800" height="600"><figcaption class="text-center text-xs mt-2 mx-36">Each local minimum distance from the origin on the ground truth trajectories is
			calculated, and the corresponding maximum sMAPE error among the windows that included
			the minimum in its target is shown. A local minimum is defined as a point at time $n$
			that is closer to the origin than the points at $n-1$ and $n+1$.</figcaption></figure> <p class="my-2 indent-8 ">As we can clearly see from the plot, Model 2 is able to predict points that are closer to
		the origin significantly more accurately than Model 1. So although Model 2 is not able to
		avoid catastraphic failure for all points, it has indeed reduced the number of points for
		which these failures occur.</p> <p class="my-2 indent-8 ">So we&#39;ve drastically increased both model capacity and dataset size, and we have only
		achieved marginal improvement on the most chaotic trajectories. To continue to make
		progress, we probably need to try a different approach. One idea is to increase the temporal
		resolution of the model by using a smaller $dt$ to generate our data points. So far we&#39;ve
		used a $dt$ of $\approx0.015$. Let&#39;s try reducing that by a factor of 5 to $\approx0.003$,
		and in order to keep the prediction task equally difficult, we&#39;ll also increase the horizon
		window, and lookback window, by a factor of 5 to 500 and 2500 respectively, so that the
		total amount of time being predicted is still $\approx1.5$ seconds. We&#39;ll call this Model
		3.</p> <div class="text-xl text-center mt-4 mb-2">Model 3</div> <section class="relative block my-4"><ul class="flex flex-col ms-16 ps-2 rounded gap-0.5 bg-gray-100 divide-y divide-gray-200"><li class="flex items-center justify-left"><div class="flex-none w-64 min-w-64">horizon</div> <div class="flex-none w-auto relative"><span class="rounded-0.5 p-1 font-mono">500</span></div> </li><li class="flex items-center justify-left"><div class="flex-none w-64 min-w-64">lookback</div> <div class="flex-none w-auto relative"><span class="rounded-0.5 p-1 font-mono">2500</span></div> </li><li class="flex items-center justify-left"><div class="flex-none w-64 min-w-64">dt</div> <div class="flex-none w-auto relative"><span class="rounded-0.5 p-1 font-mono">0.0030016</span></div> </li><li class="flex items-center justify-left"><div class="flex-none w-64 min-w-64">all other hyperparameters</div> <div class="flex-none w-auto relative"><span class="rounded-0.5 p-1 font-mono">same as Model 2</span></div> </li></ul></section> <p class="my-2 indent-0 my-4 text-sm font-serif">A sidenote on the practicality of training this model: <p class="ms-8">Although we have not increased the number of parameters relative to Model 2, by
			increasing the input size and horizon length by a factor of 5, we have significantly
			increased the memory requirement for training this model. Now in order to fit the model
			on two GPUs with 16 GB of RAM each, I have to use Lightning&#39;s <a href="https://lightning.ai/docs/pytorch/stable/advanced/model_parallel/fsdp.html" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">FSDP Strategy</a> to distribute the model across both GPUs and get the per-GPU memory requirement to be just
			a hair under 16 GB. This also means that the model trains significantly more slowly, taking
			about 40 hours to converge, compared to about 16 hours for Model 2.</p></p> <p class="my-2 indent-8 ">After retraining Model 2 with a new dataset that samples the Lorenz Attractor trajectories
		with $dt \approx 0.003$, we see that we are now able to predict all regions of the test
		set with sMAPE error $\lt80$:</p> <figure class="mb-2 self-center"><img class="m-auto" src="../Model2vModel3.png" alt="" width="600" height="600"><figcaption class="text-center text-xs mt-2 mx-36">Model 3 vs. Model 2 - sMAPE error distribution.</figcaption></figure> <p class="my-2 indent-8 ">The most challenging trajectories from the test set are significantly improved, although
		still far from perfect:</p> <figure><img class="m-auto" src="../model-3-low-dfo.gif" alt="Model 3 trajectory example" width="800" height="800"> <figcaption class="text-center text-xs mt-2 mx-36">The maximum-error trajectory from the test set for Model 3. Although there is still lots
			of room for improvement, the predictions now at least roughly track the general contour
			of the ground truth.</figcaption></figure> <p class="my-2 indent-8 ">Based on the results of Model 3, we can conclude that a primary limiting factor with
		previous models was the temporal resolution of the trajectory&#39;s history; the information
		required to make an accurate prediction for the most challenging trajectories is apparently
		not contained in trajectories with a sample period of $dt \approx 0.015$, but much more
		of it is contained in trajectories with a sample period of $dt \approx 0.003$.</p> <div class="text-xl text-center mt-4 mb-2">Autoregressive Generation</div> <p class="my-2 indent-8 ">Now that we have a model that adequately approximates the ODE given the last $\approx 7.5$
		seconds of the IVP solver&#39;s output, the next test is to measure how well the model continues
		to predict the trajectory given its own past predictions. To do this, for each trajectory in
		the test set, we will begin by using the first 2500 points to produce the model&#39;s prediction
		for points 2501-3000. Then we&#39;ll feed those 500 points back into the input to predict points
		3001-3500, and continue in this way for all 10,000 points in each trajectory. Then we can compare
		how closely the predicted trajectories match the ones produced by the IVP solver.</p><p class="my-2 indent-8 ">When we do this, we find that Model 3 is, on average, able to predict the first $\approx7.2$
		seconds of the trajectory before it begins to diverge significantly from the reference (I arrived
		at this by calculating the mean time at which the L2 distance between the trajectories exceeds
		3). But we also note that, although there are clearly visible differences between the reference
		and the prediction, the full 10,000-point trajectories that Model 3 predicts are, to the naked
		eye at least, more or less indistinguishable from the typical trajectories of the Lorenz Attractor.
		In other words, they look like entirely plausible trajectories even if they eventually diverge
		significantly from the ones produced by the IVP solver for the same initial conditions.</p> <figure class="mb-2 self-center"><img class="m-auto" src="../ref_v_ar.png" alt="Reference vs. Autoregressive Trajectories" width="450" height="500"><figcaption class="text-center text-xs mt-2 mx-36">Comparison of trajectories generated by the IVP solver (left) and auto-regressively
			generated by Model 3 (right). Each row uses the same initial conditions.</figcaption></figure> <p class="my-2 indent-8 ">Is there a way to confirm this observation more rigorously than with the eye test alone?
		I&#39;m not sure, and I&#39;ll have to leave that question for future work. But it&#39;s also crucial to
		note that different IVP solvers also produce diverging trajectories in much the same manner
		as this. In fact, all numerical solutions to chaotic equations are known to diverge from the
		true solution due to the rounding error introduced by finite precision. The <a href="https://en.wikipedia.org/wiki/Shadowing_lemma" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">shadowing lemma</a> tells us that, in spite of this, the trajectories produced by IVP solvers still remain arbitrarily
		close to real trajectories from the ODE even if they do not exactly represent the ones that would
		be produced by the given initial conditions.</p><p class="my-2 indent-8 ">In light of this, another way to evaluate the autoregressive output of our model is to
		compare it with the output from a different IVP solver with similar error constraints. <a href="https://github.com/williamgilpin/dysts" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">dysts</a> uses the <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.Radau.html" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">Radau</a> solver by default, and this is what I used to generate the dataset. <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.RK45.html#scipy.integrate.RK45" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">RK45</a> has similar error constraints to Radau, so let&#39;s compare our autoregressive output against
		Radau relative to RK45&#39;s output against Radau:</p> <figure class="mb-2 self-center"><img class="m-auto" src="../rk45_vs_nhits.png" alt="Comparison of RK45 and predictions to Radua's solutions" width="600" height="600"> <figcaption class="text-center text-xs mt-2 mx-36">Comparing the mean absolute error per timestep between Radau and Model 3 (blue) and
			Radua and RK45 (orange). The error is averaged across 200 different trajectories.
			Scipy&#39;s <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.solve_ivp.html" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">solve_ivp</a> is used to produce the IVP solver outputs.</figcaption></figure> <p class="my-2 indent-8 ">So we can say that our model is approximating the output of Radau more closely than another
		high-quality IVP solver. Ultimately, all three solvers diverge chaotically from each other,
		but in the short term, Model 3 remains closer to Radau than RK45. From this I tenatively
		conclude that our model is an effective IVP solver of the Lorenz Attractor.</p> <div class="text-xl text-center mt-4 mb-2">Conclusion</div> <p class="my-2 indent-8 ">Inspired by recent research ([<a href="https://link.aps.org/doi/10.1103/PhysRevResearch.5.043252" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">1</a>]) that supports the potential for generic
		neural architectures to match or exceed the performance of domain-specific models at the
		task of predicting chaotic systems, this project demonstrated the strong potential of at
		least one generic neural architecture ([<a href="https://arxiv.org/abs/2201.12886" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">4</a>]) to qualitatively match the
		performance of state-of-the-art IVP solvers, such as Radau, at integrating the ODE for at
		least one specific system--Lorenz--using only examples of solutions, with no explicit
		representation of the underlying ODE, to build up a model of the entire dynamics of the
		system. Given $5H$ points of an initial trajectory and at a high enough temporal resolution,
		the neural model demonstrated the ability to predict the subsequent $H$ outputs of the Radau
		solver with, in most cases, high accuracy, and in the worst case, marginal accuracy, for all
		trajectories in a test set that uniformly sampled the phase space of the system. When used autoregressively,
		the model demonstrated the potential to generate arbitrarily long trajectories that are visually
		indistinguishable from typical trajectories of the system and that match the output of the Radau
		solver at least as well as other state-of-the-art IVP solvers such as RK45.</p> <p class="my-2 indent-8 ">It must be noted, however, that the amount of data and model capacity used to achieve these
		results was substantial. Roughly 100 million data points from the Lorenz Attractor were used
		to train a model with over half a billion parameters for 40 hours using two GPUs. Although
		these numbers are modest compared to many of the most successful deep learning applications
		today, they are likely still far from trivial, in my opinion. For how many real-world
		chaotic systems with no known ODE representation is it feasible to gather 100 million data
		points? And could such a large model be optimized to run predictions in real-time for
		systems that require it to? I certainly do not know, but it seems plausible that such
		requirements could pose a significant barrier in many real-world cases. Having said all of
		that, it must also be noted that maximizing data and model efficiency was not a focus of
		this project, and so the potential for optimization is an open question.</p><p class="my-2 indent-8 ">My other, and possibly more critical, open question is, given that this model (and all IVP
		solvers) cannot actually predict the true solution but instead can only predict &#39;shadows&#39; of
		true solutions (see <a href="https://en.wikipedia.org/wiki/Shadowing_lemma" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">shadowing lemma</a>), how useful can these predictions actually be in real-world applications? Is there any
		practical use for such a system, or are projects like this merely academic exercises? Is the
		true potential of deep neural networks as applied to chaotic systems more in their ability
		to prevent systems from entering chaotic regimes, as is explored in [<a href="https://doi.org/10.1038/s41586-024-07024-9" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">2</a>]
		and [<a href="https://doi.org/10.1038/s41586-021-04301-9" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">3</a>], rather than to actually predict how chaotic dynamics will unfold?
		I suspect the answer is &#39;yes&#39;, although again I am far from certain. In either case, these
		results show a definite ability of generic deep neural networks to mimic the dynamics of a
		chaotic system, which may not amount to predicting future states but may still be enough to
		enable control systems to effectively manage those future states.</p> <div class="text-xl text-center mt-4 mb-2">References</div> <ol class="pl-5 my-2 text-xs list-decimal"><li><span class="ms-4">William Gilpin</span>, <span>Model scale versus domain knoweldge in statistical forecasting of chaotic systems</span>,
			<span>Phys. Rev. Res., vol. 5, pp. 043252, Dec</span>,
			<span>2023</span>, <span>[<a href="https://link.aps.org/doi/10.1103/PhysRevResearch.5.043252" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">link</a>]</span>.
		</li><li><span class="ms-4">Seo, J., Kim, S., Jalalvand, A. et al.</span>, <span>Avoiding fusion plasma tearing instability with deep reinforcement learning</span>,
			<span>Nature</span>,
			<span>2024</span>, <span>[<a href="https://doi.org/10.1038/s41586-024-07024-9" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">link</a>]</span>.
		</li><li><span class="ms-4">Jonas Degrave, Federico Felici, Jonas Buchli, Michael Neunert, Brendan Tracey, Francesco Carpanese, Timo Ewalds, Roland Hafner, et. al.</span>, <span>Magnetic control of tokamak plasmas through deep reinforcement learning</span>,
			<span>Nature</span>,
			<span>2021</span>, <span>[<a href="https://doi.org/10.1038/s41586-021-04301-9" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">link</a>]</span>.
		</li><li><span class="ms-4">Cristian Challu, Kin G. Olivares, Boris N. Oreshkin, Federico Garza, Max Mergenthaler-Canseco, Artur Dubrawski</span>, <span>N-HiTS: Neural Hierarchical Interpolation for Time Series Forecasting</span>,
			<span>arXiv:2201.12886</span>,
			<span>2022</span>, <span>[<a href="https://arxiv.org/abs/2201.12886" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">link</a>]</span>.
		</li><li><span class="ms-4">Boris N. Oreshkin, Dmitri Carpov, Nicolas Chapados, Yoshua Bengio</span>, <span>N-BEATS: Neural Basis Expansion Analaysis for Interpretable Time Series Forecasting</span>,
			<span>arXiv:1905.10437</span>,
			<span>2019</span>, <span>[<a href="https://arxiv.org/abs/1905.10437" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">link</a>]</span>.
		</li><li><span class="ms-4">Hinke M. Osinga</span>, <span>Understanding the geometry of dynamics: the stable manifold of the Lorenz system</span>,
			<span>Journal of the Royal Society of New Zealand</span>,
			<span>2018</span>, <span>[<a href="https://doi.org/10.1080/03036758.2018.1434802" class="font-medium text-blue-600 dark:text-blue-500 hover:underline " target="_blank" rel="noopener noreferrer">link</a>]</span>.
		</li></ol></div> 
			
			<script>
				{
					__sveltekit_123xs1d = {
						base: new URL("..", location).pathname.slice(0, -1),
						assets: "/nrxszvo.github.io"
					};

					const element = document.currentScript.parentElement;

					const data = [null,null];

					Promise.all([
						import("../_app/immutable/entry/start.DPC-yaMZ.js"),
						import("../_app/immutable/entry/app.BetbdFog.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 3],
							data,
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
	</body>
</html>
